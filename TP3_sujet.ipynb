{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP_epu_ia.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W7QSW23GYZam",
        "colab": {}
      },
      "source": [
        "!pip install SimpleITK\n",
        "!git clone https://EPU-IA-2020:GRoussy27290120EPU-IA@github.com/EPU-IA-2020/TP3.git\n",
        "%tensorflow_version 2.x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "io16YVeDYE0G",
        "colab_type": "text"
      },
      "source": [
        "  # Part 1 : Study of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWzV-qrfZ0nk",
        "colab_type": "text"
      },
      "source": [
        "First, we will study the data. \n",
        "\n",
        "The data is stored in the folder /content/epu_ia_2019/data.\n",
        "\n",
        "For a patient BraTS19_EXAMPLE, you will have a folder /content/epu_ia_2019/BraTS19_EXAMPLE. Inside this folder you will have nifti files (.nii.gz) for eacch modalities and each z slice. \n",
        "\n",
        "The train, validation and test split are stored in the folder /content/epu_ia_2019/datasets. For each split, you will have a text files with a list of patient\n",
        "\n",
        "##Exercice 1 : Train, Validation and Test Set\n",
        "\n",
        "Complete the following code to :\n",
        "*   Load the train, validation and test set\n",
        "*   Print the first 5 patients of the train set\n",
        "*   Print the lenght of the train, validation and test set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1nxaDK_Z1AS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "path = '/content/TP3/datasets/'\n",
        "train_set = np.loadtxt(path + '''CompleteHereByAString''',dtype=str)\n",
        "validation_set = np.loadtxt(path + '''CompleteHereByAString''',dtype=str)\n",
        "test_set = np.loadtxt(path + '''CompleteHereByAString''',dtype=str)\n",
        "\n",
        "# Train_set, validation_set and test_set are list of patients\n",
        "print('Train set : {}'.format('''CompleteHere''')) # Print the first 5 patients of train_set\n",
        "print('Train set lenght : {}'.format('''CompleteHere'''))\n",
        "print('Validation set lenght : {}'.format('''CompleteHere'''))\n",
        "print('Test set lenght : {}'.format('''CompleteHere'''))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8QKnQ_G3Nty",
        "colab_type": "text"
      },
      "source": [
        "[Solution](#scrollTo=u2vHeEG1yIhT&line=15&uniqifier=1)\n",
        "##Exercice 2 : Content of the data folder\n",
        "\n",
        "Complete the following code to :\n",
        "*   Print the first 5 patients in the data folder\n",
        "*   Print the lenght of the data folder\n",
        "*   Select a patient and print the number of images inside the patient folder\n",
        "* Print the number of z slices for one patient\n",
        "* Print the 5 first images of a patient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYalxEcR3OMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The data is store in the folder /content/epu_ia_2019/data/\n",
        "data_path = '/content/TP3/data/'\n",
        "files = os.listdir(data_path) # All the files in the folder /content/epu_ia_2019/data/\n",
        "print('Content of the folder : {}'.format('''CompleteHere'''))\n",
        "print('Lenght of the folder : {}'.format('''CompleteHere'''))\n",
        "\n",
        "# For each patient we have 4 modality and the segmentation in the folder :\n",
        "# t1, t2, flair, t1_ce (gado) and seg. \n",
        "# We also have a file for each slice along the z axis ()\n",
        "patient = 'BraTS19_2013_0_1/'\n",
        "patient_path = os.path.join(data_path, patient)\n",
        "patient_files = os.listdir(patient_path)\n",
        "print('Number of files for each patient : {}'.format('''CompleteHere'''))\n",
        "print('Number of slices : {}'.format('''CompleteHere'''))\n",
        "print('The first five files of the folder : {}'.format('''CompleteHere'''))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Quyx7V8lxNqi",
        "colab_type": "text"
      },
      "source": [
        "[Solution](#scrollTo=OY9dNbVY6u29)\n",
        "##Exercice 3 : Study of medical images\n",
        "\n",
        "Medical images are stored in specific data type such as dicom or nifti. \n",
        "Theses data types contain not only the images but also medical information. \n",
        "There are many Python librairy to load medical data. We will use SimpleITK.\n",
        "\n",
        "\n",
        "Complete the following code to :\n",
        "*   Print the first 5 patients in the data folder\n",
        "*   Print the lenght of the data folder\n",
        "*   Select a patient and print the number of images inside the patient folder\n",
        "* Print the number of z slices for one patient\n",
        "* Print the 5 first images of a patient\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KHGSvJkeDxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import SimpleITK as sitk\n",
        "orig_data_path = '/content/TP3/origin_data/'\n",
        "\n",
        "patients = ['BraTS19_CBICA_ANP_1', 'BraTS19_CBICA_AWV_1', 'BraTS19_TCIA01_131_1',\n",
        "            'BraTS19_TCIA10_442_1']\n",
        "\n",
        "modalities = ['_t1', '_t2', '_flair', 't1ce', 'seg']\n",
        "suffix = '.nii.gz'\n",
        "patient = patients[0]\n",
        "modality = modalities[0]\n",
        "patient_folder = os.path.join(orig_data_path,patient) \n",
        "# We use the librairy sitk to open the nifti images\n",
        "image = sitk.'''CompleteHere'''(os.path.join(patient_folder, \n",
        "                                             patient + modality + suffix))\n",
        "\n",
        "# Print type of image\n",
        "print('''CompleteHere''')\n",
        "# Print geometrical information\n",
        "print('Image Direction : {}'.format('''CompleteHere'''))\n",
        "print('Image Spacing : {}'.format('''CompleteHere'''))\n",
        "print('Image Origin : {}'.format('''CompleteHere'''))\n",
        "\n",
        "print(image.GetPixel(0, 0, 0))\n",
        "\n",
        "# Get all the information in the meta data\n",
        "keys = image.'''CompleteHere'''()\n",
        "print('Metadata :')\n",
        "for key in keys:\n",
        "  print('{} : {}'.format(key, image.'''CompleteHere'''(key)))\n",
        "\n",
        "# Convert the sitk image \n",
        "array = sitk.'''CompleteHere'''(image)\n",
        "print('''CompleteHere''') # Type of the image\n",
        "print('''CompleteHere''') #Shape\n",
        "print('''CompleteHere''') # Get value of pixel 0,0,0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTfImwXE5UVO",
        "colab_type": "text"
      },
      "source": [
        "[Solution](#scrollTo=Xr_eczPv7Jq9&line=37&uniqifier=1)\n",
        "\n",
        "## Exercice 4 : Comparaison between original data and processed data\n",
        "\n",
        "In order to accelerate the calculation time and have good results quickly, we will work on small images of shape (96, 96). The original images of the dataset have a shape (155, 240, 240) where the 155 correspond to the number of slice on the z axis.\n",
        "\n",
        "The step to pass from the original images to the images we will use are :\n",
        "- Crop the images to a shape of (155, 192, 192)\n",
        "- Downsample the images by interpolation of scale 0.5 (https://scikit-image.org/docs/dev/auto_examples/transform/plot_rescale.html) to a shape of (77, 96, 96)\n",
        "- Save all the z slice independantly in a new array of shape (96, 96)\n",
        "\n",
        "Complete the following code to plot side by side one slice of the original images and the preprocessed images. Print also the shape of the original images and the preprocessed images. You should use the functions : sitk.ReadImage, sitk.GetArrayFromImage, shape, plt.imshow, plt.title, plt.subplot\n",
        "\n",
        "Change the z parameter to plot different slice of the images "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-fAvXoprkWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "orig_data_path = '/content/TP3/origin_data/'\n",
        "patient = patients[0]\n",
        "modality = modalities[0]\n",
        "patient_folder = os.path.join('''CompleteHere''',patient) \n",
        "# We use the librairy sitk to open the nifti images\n",
        "image = sitk.'''CompleteHere'''(os.path.join('''CompleteHere''', \n",
        "                                             patient + modality + suffix))\n",
        "orig_array = sitk.'''CompleteHere'''(image)\n",
        "print('Orig array shape : {}'.format('''CompleteHere'''.shape))\n",
        "\n",
        "###\n",
        "data_path = '/content/epu_ia_2019/data/'\n",
        "patient_folder = os.path.join('''CompleteHere''',patient)\n",
        "z_slice = 35\n",
        "path = os.path.join('''CompleteHere''', patient + modality + '_z_' + str(z_slice) + suffix)\n",
        "image = sitk.'''CompleteHere'''(path)\n",
        "processed_array = sitk.'''CompleteHere'''(image)\n",
        "print('Processed array shape : {}'.format('''CompleteHere'''.shape))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow('''CompleteHere'''[z_slice*2, :, :], cmap='gray')\n",
        "plt.title('''CompleteHere''')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow('''CompleteHere''', cmap='gray')\n",
        "plt.title('''CompleteHere''')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3EVnsmHyP5Q",
        "colab_type": "text"
      },
      "source": [
        "[Solution](#scrollTo=GeuCzQ2m7PNy&line=27&uniqifier=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcVUj8KuXXfN",
        "colab_type": "text"
      },
      "source": [
        "# Part 2 : Creation of the neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xNVPBwaDZnFx"
      },
      "source": [
        "The network we will use is called UNet. It is famous network for medical image segmentation. In this part, we will create the network and train our first neural network. You can study the shape of the UNet in the figure 1 of the paper **U-Net: Convolutional Networks for Biomedical Image Segmentation** (https://arxiv.org/pdf/1505.04597.pdf). The UNet has two main features : First the size of the image is downsample by 2 in each block by a layer called <code>MaxPooling</code>. Secondly in order to keep information of high resolution, we use **skip-connection** to pass the information from the left part of the network to the right part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qDJ20x-8jPJ",
        "colab_type": "text"
      },
      "source": [
        "## Exercice 5 : Create the network\n",
        "\n",
        "- Complete the function DownConvBlock and UpConvBlock. You should use the different layers function from tensorflow which are imported in the code.\n",
        "- Try to compare the following code with the figure 1 of the paper. Where are the DownConvBlock, the UpConvBlock ?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tREoYrOcYZau",
        "colab": {}
      },
      "source": [
        "# We start by importing the different functions from Keras librairy\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (Conv2D, UpSampling2D, MaxPooling2D, Concatenate,\n",
        "                          Dropout, Input)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bQJbRxlfZmAb",
        "colab": {}
      },
      "source": [
        "def DownConvBlock(x, nConv, nChans, maxpool=False, dropout=False, \n",
        "                  activation='relu'):\n",
        "    '''\n",
        "\n",
        "    '''\n",
        "    out =  '''CompleteHere'''(nChans, 3, activation = activation, padding = 'same')(x)\n",
        "    \n",
        "    for i in range(nConv -1):\n",
        "        out = '''CompleteHere'''(nChans, 3, activation = activation, padding = 'same')(out)\n",
        "    \n",
        "    if dropout:\n",
        "        out = '''CompleteHere'''(0.5)(out)\n",
        "        \n",
        "    if maxpool:\n",
        "        maxpool = '''CompleteHere'''(pool_size=(2, 2))(out)\n",
        "        \n",
        "        return out, maxpool\n",
        "    \n",
        "    else:\n",
        "        return out \n",
        "\n",
        "def UpConvBlock(x, skip_x, nConv, nChans, dropout=False, activation='relu'):\n",
        "    '''\n",
        "\n",
        "    '''\n",
        "    out = '''CompleteHere'''(size = (2,2))(x)\n",
        "    out = '''CompleteHere'''(nChans, 2, activation = activation, \n",
        "                             padding = 'same')(out)\n",
        "    \n",
        "    merge = '''CompleteHere'''(axis=3)([out, skip_x])\n",
        "    \n",
        "    out = '''CompleteHere'''(nChans, 3, activation = activation, \n",
        "                             padding = 'same')(merge)\n",
        "    for i in range(nConv -1):\n",
        "        out = '''CompleteHere'''(nChans, 3, activation = activation, \n",
        "                                 padding = 'same')(out)\n",
        "\n",
        "    return out\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xi_jPXtGZ1-p",
        "colab": {}
      },
      "source": [
        "def unet(input_size = (256,256), n_channels=4, n_labels=4, \n",
        "         first_layer_channels=16,\n",
        "         dropout=False, activation='relu'):\n",
        "    '''\n",
        "      n_channels : number of channels of the input. \n",
        "                    By default 4, because we have 4 modalities\n",
        "      n_labels : number of channels of the ouput.\n",
        "                  By default 4 (3 labels + 1 for the background)\n",
        "      first_layer_channels : number of channels of the first convolution block\n",
        "                              The next blocks will have a multiple of this number by 2\n",
        "      dropout : use or not of droupout\n",
        "      activation : type of activation functions use\n",
        "    '''\n",
        "    inputs = Input(input_size + (n_channels,))\n",
        "    \n",
        "    channels = [first_layer_channels * (2**i) for i in range(5)]\n",
        "    channels += channels[-2::-1]\n",
        "    \n",
        "    conv1, pool1 = DownConvBlock(inputs, 2, channels[0], True, dropout, activation)\n",
        "    conv2, pool2 = DownConvBlock(pool1, 2, channels[1], True, dropout, activation)\n",
        "    conv3, pool3 = DownConvBlock(pool2, 2, channels[2], True, dropout, activation)\n",
        "    conv4, pool4 = DownConvBlock(pool3, 2, channels[3], True, dropout, activation)\n",
        "    conv5 = DownConvBlock(pool4, 2, channels[4], False, dropout, activation)\n",
        "    \n",
        "    conv6 = UpConvBlock(conv5, conv4, 2, channels[5], dropout, activation)\n",
        "    conv7 = UpConvBlock(conv6, conv3, 2, channels[6], dropout, activation)\n",
        "    conv8 = UpConvBlock(conv7, conv2, 2, channels[7], dropout, activation)\n",
        "    conv9 = UpConvBlock(conv8, conv1, 2, channels[8], dropout, activation)\n",
        "    \n",
        "    conv10 = Conv2D(32, 3, activation = 'relu', padding = 'same')(conv9)\n",
        "    conv10 = Conv2D(n_labels, 1, activation = 'softmax', padding='same')(conv10)\n",
        "\n",
        "    model = Model(inputs = inputs, outputs = conv10)\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNtCpyZv8t8L",
        "colab_type": "text"
      },
      "source": [
        "[Solution](#scrollTo=kklQ7CXx_-ns&line=40&uniqifier=1)\n",
        "\n",
        "## Exercice 6 : Study the model \n",
        "\n",
        "To study and debug a neural network, keras offers to solution : the function **summary()** which print a summary of the model and the function **plot_model** which creates a graph of the neural network. \n",
        "\n",
        "Execute the following code and answer the following question.\n",
        "- Open the image **model.png** and compare it with the figure 1 of the U-Net article\n",
        "- What are the number of convolutionnal layer in our model ?\n",
        "- What is the number of parameters in our model ?\n",
        "- What is the smallest shape in the model ? Why ?\n",
        "- What is the layer with the biggest number of parameters ? Try to find the formula to calculate the number of parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ktk3C0AWapYk",
        "colab": {}
      },
      "source": [
        "from IPython.display import SVG\n",
        "from tensorflow.keras.utils import model_to_dot, plot_model\n",
        "\n",
        "model = unet(input_size=(96,96))\n",
        "print('*************************** MODEL SUMMARY ***************************')\n",
        "print(model.summary())\n",
        "\n",
        "plot_model(model, to_file='model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyvYD-ZzAoll",
        "colab_type": "text"
      },
      "source": [
        "[Solution](#scrollTo=dj4y-_7DM7r9&line=40&uniqifier=1)\n",
        "## CODE TO EXECUTE AND HIDE\n",
        "\n",
        "All the following code is needed to execute the model, but we don't ask you to implement it. You just need to execute it once. If you want, you can try to understand what the different functions are doing but it is not needed. \n",
        "\n",
        "**Data Augmentation** : This part create functions to do the data augmentation. Data augmentation consists in create new artificial data by applying transformation such as rotation, zoom or translation. We will study it in the part 3. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLyZ0Iv8AnsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy\n",
        "import scipy.ndimage\n",
        "import numpy as np\n",
        "\n",
        "def RandomTranslation(max_translation=30, transform_matrix=None, debug=False):\n",
        "    \n",
        "    tx, ty = np.random.randint(-max_translation, max_translation, 2)\n",
        "    \n",
        "    if debug:\n",
        "        return getTranslationMatrix(tx, ty, transform_matrix), (tx, ty)\n",
        "    else:\n",
        "        return getTranslationMatrix(tx, ty, transform_matrix)\n",
        "    \n",
        "def RandomRotation(theta_max=20, transform_matrix=None, debug=False):\n",
        "    \n",
        "    theta = np.random.uniform(-theta_max, theta_max)\n",
        "    \n",
        "    if debug:\n",
        "        return getRotationMatrix(theta, transform_matrix), theta\n",
        "    else:\n",
        "        return getRotationMatrix(theta, transform_matrix)\n",
        "\n",
        "def RandomZoom(zoom_max=0.2, transform_matrix=None, debug=False):\n",
        "    \n",
        "    zoom = np.random.uniform(1 - zoom_max, 1 + zoom_max)\n",
        "    \n",
        "    if debug:\n",
        "        return getZoomMatrix(zoom, zoom, transform_matrix), zoom\n",
        "    else:\n",
        "        return getZoomMatrix(zoom, zoom, transform_matrix)\n",
        "\n",
        "def getTranslationMatrix(tx, ty, transform_matrix=None):\n",
        "    '''\n",
        "        2D translation on the axis (0, 1). \n",
        "        Axis 3 is the modality axis\n",
        "        tx: Width shift.\n",
        "        ty: Heigh shift.\n",
        "    \n",
        "    '''\n",
        "    if tx != 0 or ty != 0:\n",
        "        shift_matrix = np.array([[1, 0, 0, tx],\n",
        "                                 [0, 1, 0, ty],\n",
        "                                 [0, 0, 1, 0],\n",
        "                                 [0, 0, 0, 1]])\n",
        "    \n",
        "        if transform_matrix is None:\n",
        "            transform_matrix = shift_matrix\n",
        "        else:\n",
        "            transform_matrix = np.dot(transform_matrix, shift_matrix)\n",
        "            \n",
        "    return transform_matrix\n",
        "\n",
        "def getZoomMatrix(zx, zy, transform_matrix=None):\n",
        "    '''\n",
        "        Affine Zoom in 2D\n",
        "        zx: Zoom in x direction.\n",
        "        zy: Zoom in y direction\n",
        "    '''\n",
        "    if zx != 1 or zy != 1:\n",
        "        zoom_matrix = np.array([[zx, 0, 0, 0],\n",
        "                                [0, zy, 0, 0],\n",
        "                                [0, 0, 1, 0],\n",
        "                                [0, 0, 0, 1]])\n",
        "        if transform_matrix is None:\n",
        "            transform_matrix = zoom_matrix\n",
        "        else:\n",
        "            transform_matrix = np.dot(transform_matrix, zoom_matrix)\n",
        "            \n",
        "    return transform_matrix\n",
        "\n",
        "def getRotationMatrix(theta, transform_matrix=None):\n",
        "    '''\n",
        "        2D rotation on the axis (0, 1). \n",
        "        Axis 3 is the modality axis\n",
        "        theta: Rotation angle in degrees.\n",
        "    '''\n",
        "    if theta != 0:\n",
        "        theta = np.deg2rad(theta)\n",
        "        rotation_matrix = np.array([[np.cos(theta), -np.sin(theta), 0, 0],\n",
        "                                    [np.sin(theta), np.cos(theta), 0, 0],\n",
        "                                    [0, 0, 1, 0],\n",
        "                                    [0, 0, 0, 1]])\n",
        "        \n",
        "        if transform_matrix is None:\n",
        "            transform_matrix = rotation_matrix\n",
        "        else:\n",
        "            transform_matrix = np.dot(transform_matrix, rotation_matrix)\n",
        "    \n",
        "    return transform_matrix\n",
        "\n",
        "def apply_affine_transform(x, seg=None, transform_matrix=None, \n",
        "                           fill_mode='nearest', cval=0., order=3):\n",
        "    \"\"\"Applies an affine transformation specified by the parameters given.\n",
        "    # Arguments\n",
        "        x: 3D numpy array, single image, multimodalities (H*W*Modality)\n",
        "        fill_mode: Points outside the boundaries of the input\n",
        "            are filled according to the given mode\n",
        "            (one of `{'constant', 'nearest', 'reflect', 'wrap'}`).\n",
        "        cval: Value used for points outside the boundaries\n",
        "            of the input if `mode='constant'`.\n",
        "        order: int, order of interpolation\n",
        "    # Returns\n",
        "        The transformed version of the input.\n",
        "    \"\"\"\n",
        "    if scipy is None:\n",
        "        raise ImportError('Image transformations require SciPy. '\n",
        "                          'Install SciPy.')\n",
        "    if transform_matrix is not None:\n",
        "        \n",
        "        h, w = x.shape[0], x.shape[1]\n",
        "        \n",
        "        transform_matrix = transform_matrix_offset_center(\n",
        "            transform_matrix, h, w)\n",
        "\n",
        "        final_affine_matrix = transform_matrix[:3, :3]\n",
        "        final_offset = transform_matrix[:3, 3]\n",
        "\n",
        "        x = scipy.ndimage.interpolation.affine_transform(x, final_affine_matrix,\n",
        "            final_offset, order=order, mode=fill_mode, cval=cval)\n",
        "        \n",
        "        if seg is not None:\n",
        "            seg = scipy.ndimage.interpolation.affine_transform(seg, final_affine_matrix,\n",
        "            final_offset, order=order, mode=fill_mode, cval=cval)\n",
        "            seg[seg > 0.5] = 1\n",
        "            seg[seg < 0.5] = 0\n",
        "            \n",
        "            return x, seg \n",
        "        \n",
        "    return x\n",
        "\n",
        "def transform_matrix_offset_center(matrix, x, y):\n",
        "    o_x = float(x) / 2 + 0.5\n",
        "    o_y = float(y) / 2 + 0.5\n",
        "    offset_matrix = np.array([[1, 0, 0, o_x], \n",
        "                              [0, 1, 0 , o_y], \n",
        "                              [0, 0, 1, 0], \n",
        "                              [0, 0, 0, 1]])\n",
        "    \n",
        "    reset_matrix = np.array([[1, 0, 0, -o_x], \n",
        "                             [0, 1, 0 , -o_y], \n",
        "                             [0, 0, 1, 0], \n",
        "                             [0, 0, 0, 1]])\n",
        "    \n",
        "    transform_matrix = np.dot(np.dot(offset_matrix, matrix), reset_matrix)\n",
        "    \n",
        "    return transform_matrix\n",
        "\n",
        "def random90rotation(irm, mask, num_rot=[1, 2, 3, 4]):\n",
        "    '''\n",
        "        irm has shape (W * W * Modality)\n",
        "        mask has shape (W * H * N_Label)\n",
        "    '''\n",
        "    \n",
        "    num_rot = np.random.choice(num_rot)\n",
        "    axes = [0, 1]\n",
        "    new_img = np.rot90(irm, num_rot, axes)\n",
        "    new_mask = np.rot90(mask, num_rot, axes)\n",
        "\n",
        "    return new_img, new_mask\n",
        "    \n",
        "def axial_flip(irm, mask):\n",
        "    \n",
        "    choice_x = np.random.randint(0, 2)\n",
        "    choice_y = np.random.randint(0, 2)\n",
        "    \n",
        "    if choice_x == 1:\n",
        "        irm = irm[::-1, :, :]\n",
        "        mask = mask[::-1, :, :]\n",
        "    \n",
        "    if choice_y == 1:\n",
        "        irm = irm[:, ::-1, :]\n",
        "        mask = mask[:, ::-1, :]\n",
        "        \n",
        "    return irm, mask\n",
        "\n",
        "def normalize(array):\n",
        "\n",
        "    mean = np.mean(array[array > 0])\n",
        "    std = np.std(array[array > 0])\n",
        "\n",
        "    array = (array - mean) / std\n",
        "    array = np.clip(array, -5, 5)\n",
        "\n",
        "    mini = np.min(array)\n",
        "    maxi = np.max(array)\n",
        "\n",
        "    array = (array - mini) / (maxi - mini)\n",
        "\n",
        "    return array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1nSW0iMhcPDL"
      },
      "source": [
        "**DATASET** This part is used to automatically load the correct images, put them in batch and applying transformation. We will also load the correct train, validation and test sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1coYIDpScNmD",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow.keras as keras\n",
        "import SimpleITK as sitk\n",
        "import os\n",
        "import pandas as pd\n",
        "import sklearn.model_selection as model_selection\n",
        "import tensorflow.keras.utils\n",
        "\n",
        "\n",
        "modalities = ['_t1', '_t1ce', '_t2', '_flair']\n",
        "end = '.nii.gz'\n",
        "seg_name = '_seg'\n",
        "\n",
        "\n",
        "def generate_train_val_test(path, save_path):\n",
        "\n",
        "    brats_files = [f for f in os.listdir(path) if os.path.isdir(path + f)]\n",
        "\n",
        "    (files_train,\n",
        "     files_validation) = model_selection.train_test_split(brats_files,\n",
        "                                                          test_size=0.25,\n",
        "                                                          random_state=42)\n",
        "\n",
        "    (files_test,\n",
        "     files_validation) = model_selection.train_test_split(files_validation,\n",
        "                                                          test_size=0.3,\n",
        "                                                          random_state=42)\n",
        "\n",
        "    np.savetxt(save_path + 'train.txt', files_train, fmt='%s')\n",
        "    np.savetxt(save_path + 'val.txt', files_validation, fmt='%s')\n",
        "    np.savetxt(save_path + 'test.txt', files_test, fmt='%s')\n",
        "\n",
        "\n",
        "def load_split(split_folder):\n",
        "    '''\n",
        "        return train, val, test split with loadtxt\n",
        "    '''\n",
        "    train_split = np.loadtxt(os.path.join(\n",
        "        split_folder, 'train.txt'), dtype=str)\n",
        "    val_split = np.loadtxt(os.path.join(split_folder, 'val.txt'), dtype=str)\n",
        "    test_split = np.loadtxt(os.path.join(split_folder, 'test.txt'), dtype=str)\n",
        "\n",
        "    return train_split, val_split, test_split\n",
        "\n",
        "\n",
        "def load_sitk(path):\n",
        "\n",
        "    return sitk.GetArrayFromImage(sitk.ReadImage(path))\n",
        "\n",
        "\n",
        "def find_z_slice(list_patient, threshold, dataframe):\n",
        "\n",
        "    list_IDs = []\n",
        "\n",
        "    for patient in list_patient:\n",
        "\n",
        "        condition = dataframe[patient].values >= threshold\n",
        "        z_slice = np.where(condition)[0]\n",
        "        list_IDs += list(set([(patient, int(z//2)) for z in z_slice]))\n",
        "\n",
        "    return list_IDs\n",
        "\n",
        "\n",
        "def generate_IDs(train_split, val_split, test_plit,\n",
        "                 tumor_percentage, csv_path, image_size=(240, 240)):\n",
        "\n",
        "    tumor_volume_dataframe = pd.read_csv(csv_path)\n",
        "\n",
        "    threshold = int(tumor_percentage * np.prod(image_size) / 100)\n",
        "\n",
        "    train_IDs, val_IDs, test_IDs = [], [], []\n",
        "\n",
        "    train_IDs = find_z_slice(train_split, threshold, tumor_volume_dataframe)\n",
        "    val_IDs = find_z_slice(val_split, threshold, tumor_volume_dataframe)\n",
        "    test_IDs = find_z_slice(test_plit, threshold, tumor_volume_dataframe)\n",
        "\n",
        "    return train_IDs, val_IDs, test_IDs\n",
        "\n",
        "class DataGenerator(tensorflow.keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "\n",
        "    def __init__(self, IDs, data_path, batch_size=4, dim=(64, 64),\n",
        "                 n_channels=1, n_labels=4, shuffle=True, validation=False,\n",
        "                 data_augmentation=False, data_aug_kwargs={}):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.IDs = IDs\n",
        "        self.n_channels = n_channels\n",
        "        self.n_labels = n_labels\n",
        "\n",
        "        self.data_path = data_path\n",
        "\n",
        "        self.validation = validation\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "        if self.validation:\n",
        "            self.validation_index()\n",
        "        else:\n",
        "            self.on_epoch_end()\n",
        "\n",
        "        self.data_augmentation = data_augmentation\n",
        "        self.data_aug_kwargs = data_aug_kwargs\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        index = self.index[index *\n",
        "                           self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.IDs[i] for i in index]\n",
        "\n",
        "        # Generate data\n",
        "        irm, mask = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "        return [irm], [mask]\n",
        "\n",
        "    def validation_index(self):\n",
        "\n",
        "        self.index = list(range(len(self.IDs)))\n",
        "        np.random.shuffle(self.index)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch for training'\n",
        "\n",
        "        if not self.validation:\n",
        "            self.index = np.arange(len(self.IDs))\n",
        "\n",
        "            if self.shuffle:\n",
        "                np.random.shuffle(self.index)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "\n",
        "        # X : (n_samples, *dim, n_channels)\n",
        "        'Generates data containing batch_size samples'\n",
        "        # Initialization\n",
        "        irms = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        masks = np.empty((self.batch_size, *self.dim, self.n_labels))\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "\n",
        "            irm, mask = self.load(ID)\n",
        "            irm, mask = self.transform(irm, mask, do_normalize=True)\n",
        "\n",
        "            irms[i, ...] = irm\n",
        "            masks[i, ...] = mask\n",
        "\n",
        "        return irms, masks\n",
        "\n",
        "    def transform(self, irm, mask, do_normalize=True):\n",
        "\n",
        "\n",
        "        if self.data_augmentation:\n",
        "\n",
        "            if self.data_aug_kwargs['axial_flip']:\n",
        "                irm, mask = axial_flip(irm, mask)\n",
        "\n",
        "            if self.data_aug_kwargs['rotate90']:\n",
        "                irm, mask = random90rotation(irm, mask)\n",
        "\n",
        "            transformation_matrix = np.eye(4)\n",
        "\n",
        "            if self.data_aug_kwargs['rotation']:\n",
        "\n",
        "                theta = self.data_aug_kwargs['theta']\n",
        "                transformation_matrix = RandomRotation(theta)\n",
        "\n",
        "            if self.data_aug_kwargs['translation']:\n",
        "                max_translation = self.data_aug_kwargs['max_translation']\n",
        "\n",
        "                transformation_matrix = RandomTranslation(max_translation,\n",
        "                                                          transformation_matrix)\n",
        "\n",
        "            if self.data_aug_kwargs['zoom']:\n",
        "                max_zoom = self.data_aug_kwargs['max_zoom']\n",
        "                transformation_matrix = RandomZoom(max_zoom,\n",
        "                                                   transformation_matrix)\n",
        "                \n",
        "            (irm, mask) = apply_affine_transform(irm, mask, transformation_matrix)\n",
        "         \n",
        "        if do_normalize:\n",
        "            irm = normalize(irm)\n",
        "\n",
        "        return irm, mask\n",
        "\n",
        "    def load(self, ID):\n",
        "\n",
        "        patient, z_slice = ID\n",
        "        patient_path = os.path.join(self.data_path, patient)\n",
        "\n",
        "        irm = []\n",
        "        for modality in modalities:\n",
        "            path = os.path.join(patient_path,\n",
        "                                patient + modality + '_z_' + str(z_slice) + end)\n",
        "\n",
        "            irm.append(load_sitk(path))\n",
        "\n",
        "        irm = np.stack(irm, axis=-1)\n",
        "\n",
        "        mask_path = os.path.join(patient_path,\n",
        "                                 patient + seg_name + '_z_' + str(z_slice) + end)\n",
        "\n",
        "        mask = load_sitk(mask_path)\n",
        "        mask[mask == 4] = 3\n",
        "        mask = keras.utils.to_categorical(mask, num_classes=self.n_labels)\n",
        "\n",
        "        return irm, mask\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8BiTvbsAKAh",
        "colab_type": "text"
      },
      "source": [
        "**Tensorboard** : This part is used to plot the prediction of the network during the training and study its performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvFLBu61x_BX",
        "colab_type": "code",
        "outputId": "038c5e06-ebd0-496c-ba86-0cba100f5b4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import io\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot(irms, masks=None, pred_masks=None):\n",
        "    \n",
        "    kwargs = {'cmap': 'gray'}\n",
        "\n",
        "    fig, ax = plt.subplots(2, 3, gridspec_kw={'wspace': 0.15, 'hspace': 0.2,\n",
        "                                              'top': 0.85, 'bottom': 0.1,\n",
        "                                              'left': 0.05, 'right': 0.95})\n",
        "        \n",
        "    ax[0, 0].imshow(irms[:, :, 0], **kwargs)\n",
        "    \n",
        "    if masks is not None:\n",
        "        masks = np.argmax(masks, axis=-1)\n",
        "        ax[0, 1].imshow(masks, vmin=0, vmax=3)\n",
        "        \n",
        "    if pred_masks is not None:\n",
        "        pred_masks = np.argmax(pred_masks, axis=-1)\n",
        "        ax[0, 2].imshow(pred_masks, vmin=0, vmax=3)\n",
        "\n",
        "    for i in range(3):\n",
        "        ax[1, i].imshow(irms[:, :, i + 1], **kwargs)\n",
        "\n",
        "    for i in range(2):\n",
        "        for j in range(3):\n",
        "            ax[i, j].grid(False)\n",
        "            ax[i, j].axis('off')\n",
        "            ax[i, j].set_xticks([])\n",
        "            ax[i, j].set_yticks([])\n",
        "\n",
        "    ax[0, 0].set_title('IRM T1')\n",
        "    ax[1, 0].set_title('IRM Gado')\n",
        "    ax[1, 1].set_title('IRM T2')\n",
        "    ax[1, 2].set_title('IRM Flair')\n",
        "    \n",
        "    ax[0, 1].set_title('Ground Truth Seg')\n",
        "    ax[0, 2].set_title('Predicted Seg')\n",
        "\n",
        "    fig.canvas.draw()\n",
        "    \n",
        "    return fig\n",
        "\n",
        "def plot_to_image(figure):\n",
        "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
        "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
        "    # Save the plot to a PNG in memory.\n",
        "    buf = io.BytesIO()\n",
        "    plt.savefig(buf, format='png')\n",
        "    # Closing the figure prevents it from being displayed directly inside\n",
        "    # the notebook.\n",
        "    plt.close(figure)\n",
        "    buf.seek(0)\n",
        "    # Convert PNG buffer to TF image\n",
        "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
        "    # Add the batch dimension\n",
        "    image = tf.expand_dims(image, 0)\n",
        "    return image\n",
        "\n",
        "class TensorBoardImage(keras.callbacks.Callback):\n",
        "\n",
        "    def __init__(self, validation_generator,\n",
        "                 log_path):\n",
        "\n",
        "        super().__init__()\n",
        "        self.validation_generator = validation_generator\n",
        "        self.log_path = log_path\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "\n",
        "        # Load image\n",
        "        irms, masks = self.validation_generator.__getitem__(0)\n",
        "        \n",
        "        # Do something to the image\n",
        "        pred_masks = self.model.predict(irms)\n",
        "        masks = masks[0]\n",
        "        irms = irms[0]\n",
        "\n",
        "        batch_size = irms.shape[0]\n",
        "    \n",
        "        file_writer = tf.summary.create_file_writer(self.log_path)\n",
        "\n",
        "        for batch in range(batch_size):\n",
        "\n",
        "            fig = plot(irms[batch, ...], masks[batch, ...], pred_masks[batch, ...])\n",
        "\n",
        "            img = plot_to_image(fig)\n",
        "\n",
        "            # Using the file writer, log the reshaped image.\n",
        "            with file_writer.as_default():\n",
        "              tf.summary.image(\"Validation : \" + str(batch), \n",
        "                               img, step=epoch)\n",
        "\n",
        "        file_writer.close()\n",
        "\n",
        "        return\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yH3Zo2l9qTn",
        "colab_type": "text"
      },
      "source": [
        "**Loss** : This code is used to code the dice loss which is a loss function dedicated to medical segmentation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXuDCj_bJuu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.keras.backend as K\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    \n",
        "    smooth = 0.00001\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def generalised_dice(y_true, y_pred):\n",
        "\n",
        "    dice = 0\n",
        "    \n",
        "    for i in range(1, 4):\n",
        "        \n",
        "        dice -= dice_coef(K.cast(y_true[..., i], 'float32'), \n",
        "                          K.cast(y_pred[..., i], 'float32'))\n",
        "\n",
        "    return dice / 3\n",
        "    \n",
        "def dice_coef_metric(y_true, y_pred, numLabels=5):\n",
        "    dice=0\n",
        "    for index in range(numLabels):\n",
        "        dice = dice_coef(y_true[:,index,:,:,:], y_pred[:,index,:,:,:])\n",
        "    return dice"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CiYKEfpIcxHq"
      },
      "source": [
        "## Exercice 7 : Main - Train the model \n",
        "\n",
        "To train the model in keras, you have different steps :\n",
        "- Choose the optimiser, learning rate and loss function\n",
        "- Create the model and compile it \n",
        "- Define callbacks to save the model, plot it, change the learning rate and so on...\n",
        "- Define the data in the form of a data generator or a numpy array\n",
        "- Launch the training for a number of epochs\n",
        "\n",
        "Complete the following code and launch a training for a small number of epochs (5 or 10 for instance). \n",
        "You should see the loss decreasing. \n",
        "Then open tensorboard to visualise the decrease of the loss and the prediction of the network at the different epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d8q7mWgOcwnb",
        "colab": {}
      },
      "source": [
        "# Import of the package and choice of the parameters\n",
        "\n",
        "import tensorflow.keras\n",
        "import tensorflow.keras.utils\n",
        "import tensorflow.keras.callbacks as callbacks\n",
        "import tensorflow.keras.losses as losses\n",
        "import tensorflow.keras.optimizers as optimizers\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "\n",
        "####### Parameters of models #######\n",
        "learning_rate = 1e-4\n",
        "image_size = (96, 96)\n",
        "n_modality = 4\n",
        "n_labels = 4\n",
        "epochs = 10\n",
        "batch_size = 64\n",
        "first_layer_channels = 16\n",
        "shuffle = True\n",
        "tumor_percentage = 0.5\n",
        "tensorboard = True\n",
        "main_path = '/content/TP3/'\n",
        "sets_path = os.path.join(main_path, 'datasets/')\n",
        "csv_path = os.path.join(main_path, 'data/tumor_count.csv')\n",
        "data_path = os.path.join(main_path, 'data/')\n",
        "save_path = '/content/save/'\n",
        "loss_function = 'dice_loss'\n",
        "session_name = 'Test_session' + '_' + time.strftime('%m.%d %Hh%M')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o2f9iiY8c-sM",
        "colab": {}
      },
      "source": [
        "# loss functions : https://keras.io/losses/\n",
        "loss = generalised_dice if loss_function == 'dice_loss' else losses.categorical_crossentropy\n",
        "\n",
        "# optimizer :  https://keras.io/optimizers/\n",
        "# other optimiser available : SGD, RMSprop etc..\n",
        "optimizer = optimizers.Adam(lr='''CompleteHere''')\n",
        "\n",
        "# metrics\n",
        "model = unet(input_size='''CompleteHere''', n_channels='''CompleteHere''', \n",
        "             n_labels='''CompleteHere''', first_layer_channels='''CompleteHere''')\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='''CompleteHere''', optimizer='''CompleteHere''', metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TqkvWRgXdPkz",
        "colab": {}
      },
      "source": [
        "# Load the split, generate the IDs list and create the DataGenerator\n",
        "\n",
        "train_split, val_split, test_split = load_split(sets_path)\n",
        "(train_IDs, val_IDs,\n",
        " test_IDs) = generate_IDs(train_split, val_split, test_split,\n",
        "                          tumor_percentage, csv_path)\n",
        "\n",
        "train_Gen = DataGenerator(train_IDs, data_path, batch_size, image_size,\n",
        "                          n_channels=n_modality, n_labels=n_labels,\n",
        "                          shuffle=shuffle, validation=False)\n",
        "\n",
        "val_Gen = DataGenerator(val_IDs, data_path, batch_size, image_size,\n",
        "                        n_channels=n_modality, n_labels=n_labels,\n",
        "                        shuffle=False, validation=True)\n",
        "\n",
        "# %% Callbacks\n",
        "callbacks_list = []\n",
        "\n",
        "if tensorboard:\n",
        "\n",
        "    if not os.path.isdir(save_path + 'tensorboard_logs/'):\n",
        "        os.makedirs(save_path + 'tensorboard_logs/')\n",
        "\n",
        "    log_path = save_path + 'tensorboard_logs/' + session_name + '/'\n",
        "    if not os.path.isdir(log_path):\n",
        "      os.makedirs(log_path)\n",
        "\n",
        "    tensorboard = callbacks.TensorBoard(log_dir=log_path,\n",
        "                                        update_freq='batch')\n",
        "\n",
        "    callbacks_list.append(tensorboard)\n",
        "\n",
        "    tensorboard_image = TensorBoardImage(validation_generator=val_Gen,\n",
        "                                         log_path=log_path\n",
        "                                         )\n",
        "\n",
        "    callbacks_list.append(tensorboard_image)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3AHqde7wdTkM",
        "colab": {}
      },
      "source": [
        "# Train the model\n",
        "history = model.fit_generator('''CompleteHere''', epochs='''CompleteHere''', \n",
        "                              validation_data='''CompleteHere''', callbacks=callbacks_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT2ZKaAFw9Lo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/save/tensorboard_logs/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJPkYiVq3CTk",
        "colab_type": "text"
      },
      "source": [
        "[Solution](#scrollTo=BoChiWTrp92y&line=7&uniqifier=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KV5wjPZ_lo7",
        "colab_type": "text"
      },
      "source": [
        "# Part 3 : Data Augmentation\n",
        "\n",
        "In this part we will use data augmentation to increase the performance of the network. The idea with data augmentation is to create new artificial sample so that the network see more data and overfit less.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5zrwq0EFT-S",
        "colab_type": "text"
      },
      "source": [
        "## Exercice 8 : Study of the data augmentation\n",
        "\n",
        "Complete each of the following code to see the impact of the data augmentation. Compare the original data and the new artificial images.\n",
        "\n",
        "You should use the different functions : axial_flip, random90rotation, RandomRotation, RandomTranslation, RandomZoom"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4S28vKJ_hXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k = 3\n",
        "\n",
        "irms, masks = val_Gen.__getitem__(0)\n",
        "\n",
        "# irms is a list of a numpy array of shape [Batch * W*H*Modality]\n",
        "irms = irms[0][0]\n",
        "masks = masks[0][0]\n",
        "\n",
        "fig = plot(irms, masks)\n",
        "fig.suptitle('''CompleteHere''')\n",
        "fig.savefig(save_path + 'Orig.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDNKhDssJoJE",
        "colab_type": "text"
      },
      "source": [
        "Axial Flip "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJIcnxHDJnWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(k):\n",
        "\n",
        "    (new_irm, new_mask) = '''CompleteHere'''(irms, masks)\n",
        "\n",
        "    fig = plot(new_irm, new_mask)\n",
        "    fig.suptitle('''CompleteHere''')\n",
        "    fig.savefig(save_path + 'Axial_Flip{}.png'.format(k))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_pb5eNdJ-sh",
        "colab_type": "text"
      },
      "source": [
        "90 Rotation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZV_gkMPKBoi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(k):\n",
        "\n",
        "    (new_irm, new_mask) = '''CompleteHere'''(irms, masks)\n",
        "\n",
        "    fig = plot(new_irm, new_mask)\n",
        "    fig.suptitle('''CompleteHere''')\n",
        "    fig.savefig(save_path + 'Random90Rotation{}.png'.format(k))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJsXnMv-Fgsh",
        "colab_type": "text"
      },
      "source": [
        "Random Rotation with +/- 30"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSjJsOzdFaqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(k):\n",
        "    (transformation_matrix, theta) = '''CompleteHere'''(theta_max='''CompleteHere''', \n",
        "                                                        debug=True)\n",
        "\n",
        "    (new_irm, new_mask) = apply_affine_transform(irms, masks, transformation_matrix)\n",
        "\n",
        "    fig = plot(new_irm, new_mask)\n",
        "    fig.suptitle(' Complete Here : {:.1f}'.format(theta))\n",
        "    fig.savefig(save_path + 'Rotation{:.1f}.png'.format(theta))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGSiqebIFm0d",
        "colab_type": "text"
      },
      "source": [
        "Random Translation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZnTTCMUF-TO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(k):\n",
        "    transformation_matrix, (tx, ty) = '''CompleteHere'''(max_translation='''CompleteHere''', \n",
        "                                                         debug=True)\n",
        "\n",
        "    new_irm, new_mask = apply_affine_transform(irms, masks, transformation_matrix)\n",
        "\n",
        "    fig = plot(new_irm, new_mask)\n",
        "    fig.suptitle(' Complete Here : x={} y={}'.format(tx, ty))\n",
        "    fig.savefig(save_path + 'Translation_{}_{}.png'.format(tx, ty))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWO-77u0F-1j",
        "colab_type": "text"
      },
      "source": [
        "Random Zoom"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q4YHSk8GJcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(k):\n",
        "    (transformation_matrix, zoom) = '''CompleteHere'''(zoom_max='''CompleteHere''', \n",
        "                                                       debug=True)\n",
        "\n",
        "    (new_irm, new_mask) = apply_affine_transform(irms, masks, transformation_matrix)\n",
        "\n",
        "    fig = plot(new_irm, new_mask)\n",
        "    fig.suptitle(' Complete Here : {:.2f}'.format(zoom))\n",
        "    fig.savefig(save_path + 'Zoom_{:.2f}.png'.format(zoom))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fytm3C4GbZU",
        "colab_type": "text"
      },
      "source": [
        "All transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNzPoFz5GbLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(k):\n",
        "    (transformation_matrix, theta) = '''CompleteHere'''(theta_max='''CompleteHere''', \n",
        "                                                        debug=True)\n",
        "    \n",
        "    transformation_matrix, (tx, ty) = '''CompleteHere'''(max_translation='''CompleteHere''', \n",
        "                                                         debug=True)\n",
        "    \n",
        "    (transformation_matrix, zoom) = '''CompleteHere'''(zoom_max='''CompleteHere''', \n",
        "                                                       debug=True)\n",
        "\n",
        "    (new_irm,\n",
        "      new_mask) = apply_affine_transform(irms, masks, transformation_matrix)\n",
        "\n",
        "    fig = plot(new_irm, new_mask)\n",
        "    fig.suptitle('Rotation : {:.1f} Translation : {}::{} Zoom : {:.2f}'.format(theta, tx, ty,zoom))\n",
        "    fig.savefig(save_path + 'All_transforms{}.png'.format(i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKzwb5U33dzL",
        "colab_type": "text"
      },
      "source": [
        "[Solution](#scrollTo=37wKpCWCqFeL&line=7&uniqifier=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaqqV3VeGngd",
        "colab_type": "text"
      },
      "source": [
        "## Exercice 9 : Train with data augmentation\n",
        "\n",
        "Relaunch a new training with data augmentation. The training will take more time than during the previous training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqiwTM46GnQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_augmentation=True\n",
        "data_aug_kwargs = {'rotation': True, 'theta':'''CompleteHere''', \n",
        "                    'zoom' : True, 'max_zoom':'''CompleteHere''',\n",
        "                    'translation':True, 'max_translation':'''CompleteHere''',\n",
        "                    'rotate90':True, 'axial_flip':True}\n",
        "\n",
        "train_Gen = DataGenerator(train_IDs, data_path, batch_size, image_size,\n",
        "                                  n_channels=n_modality, n_labels=n_labels,\n",
        "                                  shuffle=shuffle, validation=False,\n",
        "                                  data_augmentation=data_augmentation,\n",
        "                                  data_aug_kwargs=data_aug_kwargs)\n",
        "\n",
        "val_Gen = DataGenerator(val_IDs, data_path, batch_size, image_size,\n",
        "                                n_channels=n_modality, n_labels=n_labels,\n",
        "                                shuffle=False, validation=True)\n",
        "\n",
        "model.fit_generator(train_Gen, epochs=epochs, validation_data=val_Gen,\n",
        "                    callbacks=callbacks_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAXgyJdK4UcM",
        "colab_type": "text"
      },
      "source": [
        "## Exercice 10 : Comparaison of training curves\n",
        "\n",
        "Two models trained for 200 epochs are given in the folder /content/TP3/tensorboard_logs/. The only difference between the two models in that one is using data augmentation and the other not. \n",
        "Open tensorboard and compare the loss, accuracy and prediction for the two models.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKm98J2jIUHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir /content/TP3/tensorboard_logs/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2kqcqsLqIQm",
        "colab_type": "text"
      },
      "source": [
        "# Part 4 : Prediction and Evaluation\n",
        "\n",
        "After training the model we have to perform two steps : the prediction of the segmentation using a model trained and the evaluation of the performance of the network.\n",
        "\n",
        "The evaluation of the network should be done on the validation set (which have not been seen by the network during the training). The test set will only be used when all the parameters of the network are chosen. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnTIU3BrlhsY",
        "colab_type": "text"
      },
      "source": [
        "## Exercice 11 : Prediction and returning to original space\n",
        "\n",
        "In this exercice, we will load a network and use the function **predict()** to calculate the predicted segmentation. The predicted segmentation will have a shape (96, 96, 4). We need to transform it back to the 3D shape (155, 240, 240) to perform the evaluation. \n",
        "The steps to calculate the prediction will be : \n",
        "- Load an image X, with the function **load_image**\n",
        "- Apply **model.predict()** on X\n",
        "- Apply **get_mask2original_shape()** to the prediction\n",
        "\n",
        "**Questions**\n",
        "- Study the function **load_image(patient)**. Try to understand what this function is doing. Try to guess the shape of all the different variable (temp_array, array, X). Then use the function **print** and **shape** to verify your guess. \n",
        "- Study the function **get_mask2original_shape()**. What are doing the different functions inside it ? Try to guess the different shape\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vO2Km0fZoND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First we load the network \n",
        "import tensorflow as tf\n",
        "model_path = '/content/TP3/models/Classic_Training_with_Dice_200_epochs_data_augmentation_01.23 16h48/models_epoch_200_loss_-0.60.hdf5'\n",
        "\n",
        "# returns a compiled model identical to the previous one\n",
        "custom_objects={'generalised_dice': generalised_dice}\n",
        "model = tf.keras.models.load_model(model_path, custom_objects=custom_objects)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZCvDnZToenj",
        "colab_type": "code",
        "outputId": "f272a2e5-7179-490f-bb63-30444faec2ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "import os \n",
        "import numpy as np \n",
        "import SimpleITK as sitk\n",
        "import skimage.transform\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "test_path = '/content/TP3/origin_data/'\n",
        "data_path = '/content/TP3/data/'\n",
        "patients = os.listdir(test_path)\n",
        "patient = patients[1]\n",
        "z_max = 77\n",
        "\n",
        "modalities = ['_t1', '_t1ce', '_t2', '_flair']\n",
        "suffix = '.nii.gz'\n",
        "\n",
        "# Print shape of different variables\n",
        "def load_image(patient):\n",
        "  patient_folder = os.path.join(data_path,patient)\n",
        "  X = []\n",
        "  for z in range(z_max):\n",
        "    temp_array = []\n",
        "    for modality in modalities:\n",
        "\n",
        "      image = sitk.ReadImage(os.path.join(patient_folder, \n",
        "                                        patient  + modality + '_z_' + str(z) + suffix))\n",
        "      array = sitk.GetArrayFromImage(image) \n",
        "      temp_array.append(array)\n",
        "\n",
        "    temp_array = np.stack(temp_array, axis=-1)\n",
        "  \n",
        "    # Don't forget to normalize your data\n",
        "    temp_array = normalize(temp_array)\n",
        "    X.append(temp_array)\n",
        "\n",
        "  X = np.stack(X, axis=0)\n",
        "  return X\n",
        "\n",
        "# Print shape of different variables\n",
        "def get_mask2original_shape(predict_mask):\n",
        "  \n",
        "  mask = np.zeros(shape=(155,240, 240))\n",
        "  res = skimage.transform.resize(predict_mask, (155, 192, 192, 4))\n",
        "  res = res > 0.5\n",
        "  res = np.argmax(res, axis=-1)\n",
        "  mask[:, 24:-24, 24:-24] = res\n",
        "  mask[mask == 3] = 4\n",
        "  return mask.astype('int')\n",
        "\n",
        "X = load_image(patient)\n",
        "predict_mask = model.predict(X, batch_size=16)\n",
        "predict_mask = get_mask2original_shape(predict_mask)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:181: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(77, 96, 96, 4)\n",
            "Shape after rescale : (155, 192, 192, 4)\n",
            "(155, 240, 240)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnsheSoglQM-",
        "colab_type": "text"
      },
      "source": [
        "[Solution](#scrollTo=gGcVKKoZm8If)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjT3WF0el3yb",
        "colab_type": "text"
      },
      "source": [
        "## Exercice 12 : Visual Comparaison\n",
        "\n",
        "We will do a visual comparaison between the predicted mask and the groundtruth. We will perform the comparaison with **Matplotlib** (python librariry for graph) and a software specialised for medical imaging vizualisation **3D Slicer** (https://www.slicer.org/)\n",
        "\n",
        "**Questions**\n",
        "- Load the groundtruth mask (in folder /content/TP3/origin_data) and using the function **plt.subplot**, **plt.imshow** and **plt.title**, plot the predicted mask and the groundtruth side by side\n",
        "- Change the value of the **z_slice** parameter to explore the segmentation slice by slice\n",
        "- Study the function **numpy2nifti**. What does it do ? Apply it and save the predicted mask as a nifti files. Download the MRI, the groundtruth segmentation and the predicted segmentation and download the software 3D Slicer. Open the nifti files in 3D Slicer and compare the images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKSDSeAkaBmC",
        "colab_type": "code",
        "outputId": "484358a8-80d1-4016-e70b-b94d6bc41dc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "# Compare visual plot of prediction and original mask \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "patient_folder = os.path.join(test_path,patient)\n",
        "orig_image = sitk.'''CompleteHere'''(os.path.join(patient_folder, \n",
        "                                                  patient  + '_seg' + suffix))\n",
        "orig_mask = sitk.'''CompleteHere'''(orig_image)\n",
        "\n",
        "z_slice=90\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow('''CompleteHere'''[z_slice, :,: ], vmin=0, vmax=4)\n",
        "plt.title('Original mask (slice {})'.format(z_slice))\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow('''CompleteHere'''[z_slice, :,: ], vmin=0, vmax=4)\n",
        "plt.title('Predicted mask (slice {})'.format(z_slice))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Predicted mask (slice 90)')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAADHCAYAAADifRM/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A3-sCKcDtp0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def numpy2sitk(predict_mask, orig_img):\n",
        "  '''\n",
        "    Input : predict_mask of type numpy array\n",
        "            orig_img of type SimpleITK image\n",
        "    Output : new_img of type SimpleITK image \n",
        "  '''\n",
        "  new_img = sitk.GetImageFromArray(predict_mask)\n",
        "  new_img.SetDirection(orig_img.GetDirection())\n",
        "  new_img.SetOrigin(orig_img.GetOrigin())\n",
        "  new_img.SetSpacing(orig_img.GetSpacing())\n",
        "  return new_img\n",
        "\n",
        "predict_img = '''CompleteHere'''(predict_mask, orig_image)\n",
        "path = os.path.join(patient_folder, patient + '_predict_seg' + suffix)\n",
        "sitk.'''CompleteHere'''(predict_img, path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFHA-cT4kybj",
        "colab_type": "text"
      },
      "source": [
        "[Solution](#scrollTo=JVwUv_NEm8ha&line=7&uniqifier=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saALPYgDmFzt",
        "colab_type": "text"
      },
      "source": [
        "## Exercice 13 : Metrics \n",
        "\n",
        "We will now calculate the evaluation metrics to assess the performance of our model. We will use 3 metrics : the sensitivity (also called true positive rate), the Specificity (also called true negative rate) and the dice score (different of the dice loss used during the training). \n",
        "\n",
        "We will evaluate the metrics on the 5 patients in the folder /content/TP3/origin_data. In the reality, we should evaluate the metrics for all the patient of the validation set (the test set will only be used when we choose the best model and we publish our results).\n",
        "\n",
        "**Questions :**\n",
        "- Using the previous **predict_mask** and **orig_mask** array, calculate the metrics. You just need to apply the function **evalAllSample()**. Print the result. \n",
        "- Using, a for loop and all the functions defined in the part 4, calculate the metrics for the 5 patients in the folder /content/TP3/origin_data. You should print the average Dice value for each category (WT, ET, TC) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebE_L5HE-LXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def metrics(mask_, gt_):\n",
        "  '''\n",
        "    Taking to binary array of same shape as input\n",
        "    This function compute the confusion matrix and use it to calculate \n",
        "    Dice metrics, Sensitivity and Specificity\n",
        "    Input : mask_, gt_ numpy array of identic shape (only 1 and 0)\n",
        "    Output : List of 3 scores\n",
        "  '''\n",
        "  lnot = np.logical_not\n",
        "  land = np.logical_and\n",
        "\n",
        "  true_positive = np.sum(land((mask_), (gt_)))\n",
        "  false_positive = np.sum(land((mask_), lnot(gt_)))\n",
        "  false_negative = np.sum(land(lnot(mask_), (gt_)))\n",
        "  true_negative = np.sum(land(lnot(mask_), lnot(gt_)))\n",
        "\n",
        "  M = np.array([[true_negative, false_negative],\n",
        "                [false_positive, true_positive]]).astype(np.float64)\n",
        "  metrics = {}\n",
        "  metrics['Sensitivity'] = M[1, 1] / (M[0, 1] + M[1, 1])\n",
        "  metrics['Specificity'] = M[0, 0] / (M[0, 0] + M[1, 0])\n",
        "  metrics['Dice'] = 2 * M[1, 1] / (M[1, 1] * 2 + M[1, 0] + M[0, 1])\n",
        "  # metrics may be NaN if denominator is zero! use np.nanmean() while\n",
        "  # computing average to ignore NaNs.\n",
        "\n",
        "  return [metrics['Dice'], metrics['Sensitivity'], metrics['Specificity']]\n",
        "\n",
        "\n",
        "def evalAllSample(mask_, gt_):\n",
        "  '''\n",
        "    This functions takes as input two numpy array with labels between\n",
        "    0, 1, 2 and 4 and calculate the metrics as defined in BraTS data challenge\n",
        "    mask_ and gt_ should be array of int\n",
        "  '''\n",
        "  # whole tumor (labels 1,2,4)\n",
        "  mask_wt, gt_wt = (np.array([0, 1, 1, 0, 1])[mask_], \n",
        "                    np.array([0, 1, 1, 0, 1])[gt_])\n",
        "  wt_metrics = metrics(mask_wt, gt_wt)\n",
        "\n",
        "  # tumor core (labels 1,4)\n",
        "  mask_tc, gt_tc = (np.array([0, 1, 0, 0, 1])[mask_], \n",
        "                    np.array([0, 1, 0, 0, 1])[gt_])\n",
        "  tc_metrics = metrics(mask_tc, gt_tc)\n",
        "\n",
        "  # enhancing tumor (label 4)\n",
        "  mask_et, gt_et = (np.array([0, 0, 0, 0, 1])[mask_], \n",
        "                    np.array([0, 0, 0, 0, 1])[gt_])\n",
        "  et_metrics = metrics(mask_et, gt_et)\n",
        "  \n",
        "  return pd.DataFrame({'wt': wt_metrics, 'tc': tc_metrics, 'et': et_metrics},\n",
        "                      index=['Dice', 'Sensitivity', 'Specificity'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLCmi1oC-t8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wt_dice_list = []\n",
        "et_dice_list = []\n",
        "tc_dice_list = []\n",
        "\n",
        "for patient in patients:\n",
        "\n",
        "  patient_folder = os.path.join(test_path,patient)\n",
        "  orig_image = '''CompleteHere'''(os.path.join(patient_folder, \n",
        "                                           patient  + '_seg' + suffix))\n",
        "  orig_mask = '''CompleteHere'''\n",
        "\n",
        "  X = '''CompleteHere'''\n",
        "  predict_mask = '''CompleteHere'''\n",
        "  predict_mask = g'''CompleteHere'''\n",
        "  \n",
        "  print('*********** {} ***********'.format(patient))\n",
        "  scores = '''CompleteHere'''\n",
        "  print(scores)\n",
        "  print()\n",
        "\n",
        "  '''CompleteHere'''.append('''CompleteHere'''.loc['Dice', 'wt'])\n",
        "  '''CompleteHere'''.append('''CompleteHere'''.loc['Dice', 'et'])\n",
        "  '''CompleteHere'''.append('''CompleteHere'''.loc['Dice', 'tc'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlCr9vpxO1-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Whole Tumor Dice : {:.2f}'.format('''CompleteHere'''))\n",
        "print('Tumor Core Dice : {:.2f}'.format('''CompleteHere'''))\n",
        "print('Enhancing Tumor Dice : {:.2f}'.format('''CompleteHere'''))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mt9h1_7loyOg",
        "colab_type": "text"
      },
      "source": [
        "[Solution](#scrollTo=r_pVQq5zm_3f&line=5&uniqifier=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YqJqcAxI6Te",
        "colab_type": "text"
      },
      "source": [
        "# Part 5 : Subsidiary Question\n",
        "\n",
        "Without using the code given in the exercice 5, implement yourself the unet, using the different layers from the keras library and the article : https://arxiv.org/pdf/1505.04597.pdf\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bgq1CH8PJLam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def unet(input_size = (256,256,1)):\n",
        "  '''\n",
        "  \n",
        "  CompleteHere\n",
        "  \n",
        "  '''\n",
        "  model = Model(input = inputs, output = conv10)\n",
        "\n",
        "  return model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X413Q0cUkQ2i",
        "colab_type": "text"
      },
      "source": [
        "[Solution](#scrollTo=hk4LQJOXnBaE&line=56&uniqifier=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdRG-mgdXg0u",
        "colab_type": "text"
      },
      "source": [
        "# Part 6 : Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2vHeEG1yIhT",
        "colab_type": "text"
      },
      "source": [
        " ## Exercice 1\n",
        "\n",
        "```python\n",
        "/import numpy as np\n",
        "import os\n",
        "path = '/content/epu_ia_2019/'\n",
        "train_set = np.loadtxt(path + 'datasets/train.txt',dtype=str)\n",
        "validation_set = np.loadtxt(path + 'datasets/val.txt',dtype=str)\n",
        "test_set = np.loadtxt(path + 'datasets/test.txt',dtype=str)\n",
        "\n",
        "# Train_set, validation_set and test_set are list of patients\n",
        "print('Train set : {}'.format(train_set[:5])) # Print the first 5 patients of train_set\n",
        "print('Train set lenght : {}'.format(len(train_set)))\n",
        "print('Validation set lenght : {}'.format(len(validation_set)))\n",
        "print('Test set lenght : {}'.format(len(test_set)))\n",
        "```\n",
        "\n",
        "[Return to code](#scrollTo=pWzV-qrfZ0nk)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OY9dNbVY6u29",
        "colab_type": "text"
      },
      "source": [
        " ## Exercice 2\n",
        "```python\n",
        "# The data is store in the folder /content/epu_ia_2019/data/\n",
        "data_path = '/content/epu_ia_2019/data/'\n",
        "files = os.listdir(data_path) # All the files in the folder /content/epu_ia_2019/data/\n",
        "print('Content of the folder : {}'.format(files[:5]))\n",
        "print('Lenght of the folder : {}'.format(len(files)))\n",
        "\n",
        "# For each patient we have 4 modality and the segmentation in the folder :\n",
        "# t1, t2, flair, t1_ce (gado) and seg. \n",
        "# We also have a file for each slice along the z axis ()\n",
        "patient = 'BraTS19_2013_0_1/'\n",
        "patient_path = os.path.join(data_path, patient)\n",
        "patient_files = os.listdir(patient_path)\n",
        "print('Number of files for each patient : {}'.format(len(patient_files) ))\n",
        "print('Number of slices : {}'.format(len(patient_files) / 5))\n",
        "print('The first five files of the folder : {}'.format(patient_files[:5]))\n",
        "```\n",
        "\n",
        "[Return to code](#scrollTo=K8QKnQ_G3Nty)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr_eczPv7Jq9",
        "colab_type": "text"
      },
      "source": [
        " ## Exercice 3\n",
        "```python\n",
        "import os\n",
        "import SimpleITK as sitk\n",
        "orig_data_path = '/content/epu_ia_2019/origin_data/'\n",
        "\n",
        "patients = ['BraTS19_CBICA_ANP_1', 'BraTS19_CBICA_AWV_1', 'BraTS19_TCIA01_131_1',\n",
        "            'BraTS19_TCIA10_442_1']\n",
        "\n",
        "modalities = ['_t1', '_t2', '_flair', 't1ce', 'seg']\n",
        "suffix = '.nii.gz'\n",
        "patient = patients[0]\n",
        "modality = modalities[0]\n",
        "patient_folder = os.path.join(orig_data_path,patient) \n",
        "# We use the librairy sitk to open the nifti images\n",
        "image = sitk.ReadImage(os.path.join(patient_folder, patient + modality + suffix))\n",
        "\n",
        "print(type(image))\n",
        "# Print geometrical information\n",
        "print('Image Direction : {}'.format(image.GetDirection()))\n",
        "print('Image Spacing : {}'.format(image.GetSpacing()))\n",
        "print('Image Origin : {}'.format(image.GetOrigin()))\n",
        "\n",
        "print(image.GetPixel(0, 0, 0))\n",
        "\n",
        "# Get all the information in the meta data\n",
        "keys = image.GetMetaDataKeys()\n",
        "print('Metadata :')\n",
        "for key in keys:\n",
        "  print('{} : {}'.format(key, image.GetMetaData(key)))\n",
        "\n",
        "# Convert the sitk image \n",
        "array = sitk.GetArrayFromImage(image)\n",
        "print(type(array)) # Type of the image\n",
        "print(array.shape)\n",
        "print(array[0, 0, 0])\n",
        "```\n",
        "\n",
        "[Return to code](#scrollTo=Quyx7V8lxNqi&line=3&uniqifier=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeuCzQ2m7PNy",
        "colab_type": "text"
      },
      "source": [
        " ## Exercice 4\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "orig_data_path = '/content/epu_ia_2019/origin_data/'\n",
        "patient = patients[0]\n",
        "modality = modalities[0]\n",
        "patient_folder = os.path.join(orig_data_path,patient) \n",
        "# We use the librairy sitk to open the nifti images\n",
        "image = sitk.ReadImage(os.path.join(patient_folder, patient + modality + suffix))\n",
        "orig_array = sitk.GetArrayFromImage(image)\n",
        "print('Orig array shape : {}'.format(orig_array.shape))\n",
        "\n",
        "###\n",
        "data_path = '/content/epu_ia_2019/data/'\n",
        "patient_folder = os.path.join(data_path,patient)\n",
        "z_slice = 35\n",
        "path = os.path.join(patient_folder, patient + modality + '_z_' + str(z_slice) + suffix)\n",
        "image = sitk.ReadImage(path)\n",
        "processed_array = sitk.GetArrayFromImage(image)\n",
        "print('Processed array shape : {}'.format(processed_array.shape))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(orig_array[z_slice*2, :, :], cmap='gray')\n",
        "plt.title('Original array')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(processed_array, cmap='gray')\n",
        "plt.title('Processed array')\n",
        "```\n",
        "\n",
        "[Return to code](#scrollTo=CTfImwXE5UVO)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kklQ7CXx_-ns",
        "colab_type": "text"
      },
      "source": [
        " ## Exercice 5\n",
        "```python\n",
        "\n",
        "def DownConvBlock(x, nConv, nChans, maxpool=False, dropout=False, \n",
        "                  activation='relu'):\n",
        "    '''\n",
        "\n",
        "    '''\n",
        "    out =  Conv2D(nChans, 3, activation = activation, padding = 'same')(x)\n",
        "    \n",
        "    for i in range(nConv -1):\n",
        "        out = Conv2D(nChans, 3, activation = activation, padding = 'same')(out)\n",
        "    \n",
        "    if dropout:\n",
        "        out = Dropout(0.5)(out)\n",
        "        \n",
        "    if maxpool:\n",
        "        maxpool = MaxPooling2D(pool_size=(2, 2))(out)\n",
        "        \n",
        "        return out, maxpool\n",
        "    \n",
        "    else:\n",
        "        return out \n",
        "\n",
        "def UpConvBlock(x, skip_x, nConv, nChans, dropout=False, activation='relu'):\n",
        "    '''\n",
        "\n",
        "    '''\n",
        "    out = UpSampling2D(size = (2,2))(x)\n",
        "    out = Conv2D(nChans, 2, activation = activation, padding = 'same')(out)\n",
        "    \n",
        "    merge = Concatenate(axis=3)([out, skip_x])\n",
        "    \n",
        "    out = Conv2D(nChans, 3, activation = activation, padding = 'same')(merge)\n",
        "    for i in range(nConv -1):\n",
        "        out = Conv2D(nChans, 3, activation = activation, padding = 'same')(out)\n",
        "\n",
        "    return out\n",
        "```\n",
        "\n",
        "[Return to code](#scrollTo=5qDJ20x-8jPJ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dj4y-_7DM7r9",
        "colab_type": "text"
      },
      "source": [
        " ## Exercice 6\n",
        "```python\n",
        "\n",
        "def DownConvBlock(x, nConv, nChans, maxpool=False, dropout=False, \n",
        "                  activation='relu'):\n",
        "    '''\n",
        "\n",
        "    '''\n",
        "    out =  Conv2D(nChans, 3, activation = activation, padding = 'same')(x)\n",
        "    \n",
        "    for i in range(nConv -1):\n",
        "        out = Conv2D(nChans, 3, activation = activation, padding = 'same')(out)\n",
        "    \n",
        "    if dropout:\n",
        "        out = Dropout(0.5)(out)\n",
        "        \n",
        "    if maxpool:\n",
        "        maxpool = MaxPooling2D(pool_size=(2, 2))(out)\n",
        "        \n",
        "        return out, maxpool\n",
        "    \n",
        "    else:\n",
        "        return out \n",
        "\n",
        "def UpConvBlock(x, skip_x, nConv, nChans, dropout=False, activation='relu'):\n",
        "    '''\n",
        "\n",
        "    '''\n",
        "    out = UpSampling2D(size = (2,2))(x)\n",
        "    out = Conv2D(nChans, 2, activation = activation, padding = 'same')(out)\n",
        "    \n",
        "    merge = Concatenate(axis=3)([out, skip_x])\n",
        "    \n",
        "    out = Conv2D(nChans, 3, activation = activation, padding = 'same')(merge)\n",
        "    for i in range(nConv -1):\n",
        "        out = Conv2D(nChans, 3, activation = activation, padding = 'same')(out)\n",
        "\n",
        "    return out\n",
        "```\n",
        "\n",
        "[Return to code](#scrollTo=LNtCpyZv8t8L)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BoChiWTrp92y"
      },
      "source": [
        "## Exercice 7\n",
        "```python\n",
        "# loss functions : https://keras.io/losses/\n",
        "loss = generalised_dice if loss_function == 'dice_loss' else losses.categorical_crossentropy\n",
        "\n",
        "# optimizer :  https://keras.io/optimizers/\n",
        "# other optimiser available : SGD, RMSprop etc..\n",
        "optimizer = optimizers.Adam(lr=learning_rate)\n",
        "\n",
        "# metrics\n",
        "model = unet(image_size, n_modality, n_labels, first_layer_channels)\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Train the model\n",
        "history = model.fit_generator(train_Gen, epochs=epochs, validation_data=val_Gen, callbacks=callbacks_list)\n",
        "\n",
        "```\n",
        "\n",
        "[Return to code](#scrollTo=CiYKEfpIcxHq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37wKpCWCqFeL",
        "colab_type": "text"
      },
      "source": [
        "## Exercice 8\n",
        "```python\n",
        "k = 3\n",
        "\n",
        "irms, masks = val_Gen.__getitem__(0)\n",
        "\n",
        "# irms is a list of a numpy array of shape [Batch * W*H*Modality]\n",
        "irms = irms[0][0]\n",
        "masks = masks[0][0]\n",
        "\n",
        "fig = plot(irms, masks)\n",
        "fig.suptitle('Original image')\n",
        "fig.savefig(save_path + 'Orig.png')\n",
        "\n",
        "#Axial Flip\n",
        "for i in range(k):\n",
        "\n",
        "    (new_irm, new_mask) = axial_flip(irms, masks)\n",
        "\n",
        "    fig = plot(new_irm, new_mask)\n",
        "    fig.suptitle('Random Axial Flip')\n",
        "    fig.savefig(save_path + 'Axial_Flip{}.png'.format(k))\n",
        "\n",
        "# 90 Rotation\n",
        "for i in range(k):\n",
        "\n",
        "    (new_irm, new_mask) = random90rotation(irms, masks)\n",
        "\n",
        "    fig = plot(new_irm, new_mask)\n",
        "    fig.suptitle('Random 90 Rotation')\n",
        "    fig.savefig(save_path + 'Random90Rotation{}.png'.format(k))\n",
        "\n",
        "# Random Rotation +/-30\n",
        "for i in range(k):\n",
        "    (transformation_matrix, theta) = RandomRotation(30, debug=True)\n",
        "\n",
        "    (new_irm, new_mask) = apply_affine_transform(irms, masks, transformation_matrix)\n",
        "\n",
        "    fig = plot(new_irm, new_mask)\n",
        "    fig.suptitle('Random rotation : {:.1f}'.format(theta))\n",
        "    fig.savefig(save_path + 'Rotation{:.1f}.png'.format(theta))\n",
        "\n",
        "# Translation\n",
        "for i in range(k):\n",
        "    transformation_matrix, (tx, ty) = RandomTranslation(30, debug=True)\n",
        "\n",
        "    new_irm, new_mask = apply_affine_transform(irms, masks, transformation_matrix)\n",
        "\n",
        "    fig = plot(new_irm, new_mask)\n",
        "    fig.suptitle('Random translation : x={} y={}'.format(tx, ty))\n",
        "    fig.savefig(save_path + 'Translation_{}_{}.png'.format(tx, ty))\n",
        "\n",
        "# Zoom \n",
        "for i in range(k):\n",
        "    (transformation_matrix, zoom) = RandomZoom(0.5, debug=True)\n",
        "\n",
        "    (new_irm, new_mask) = apply_affine_transform(irms, masks, transformation_matrix)\n",
        "\n",
        "    fig = plot(new_irm, new_mask)\n",
        "    fig.suptitle('Random zoom : {:.2f}'.format(zoom))\n",
        "    fig.savefig(save_path + 'Zoom_{:.2f}.png'.format(zoom))\n",
        "\n",
        "# All transformations\n",
        "for i in range(k):\n",
        "    (transformation_matrix, theta) = RandomRotation(30, debug=True)\n",
        "    \n",
        "    (transformation_matrix, \n",
        "     (tx, ty)) = RandomTranslation(30,  transformation_matrix, debug=True)\n",
        "    \n",
        "    (transformation_matrix,\n",
        "      zoom) = RandomZoom(0.5, transformation_matrix, debug=True)\n",
        "\n",
        "    (new_irm,\n",
        "      new_mask) = apply_affine_transform(irms, masks, transformation_matrix)\n",
        "\n",
        "    fig = plot(new_irm, new_mask)\n",
        "    fig.suptitle('Rotation : {:.1f} Translation : {}::{} Zoom : {:.2f}'.format(theta, tx, ty,zoom))\n",
        "    fig.savefig(save_path + 'All_transforms{}.png'.format(i))\n",
        "```\n",
        "\n",
        "[Return to code](#scrollTo=U5zrwq0EFT-S)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gGcVKKoZm8If"
      },
      "source": [
        "## Exercice 11\n",
        "```python\n",
        "def load_image(patient):\n",
        "  patient_folder = os.path.join(data_path,patient)\n",
        "  X = []\n",
        "  for z in range(z_max):\n",
        "    temp_array = []\n",
        "    for modality in modalities:\n",
        "\n",
        "      image = sitk.ReadImage(os.path.join(patient_folder, \n",
        "                                        patient  + modality + '_z_' + str(z) + suffix))\n",
        "      array = sitk.GetArrayFromImage(image) # Array as the shape 96 * 96 \n",
        "      temp_array.append(array)\n",
        "\n",
        "    temp_array = np.stack(temp_array, axis=-1) # Shape 96 * 96 * 4 (we stack the 4 modality together)\n",
        "  \n",
        "    # Don't forget to normalize your data\n",
        "    temp_array = normalize(temp_array)\n",
        "    X.append(temp_array)\n",
        "\n",
        "  X = np.stack(X, axis=0) # Shape 77 * 96 * 96 * 4 (we stack the slice together)\n",
        "  return X\n",
        "\n",
        "def get_mask2original_shape(predict_mask):\n",
        "  \n",
        "  mask = np.zeros(shape=(155,240, 240))\n",
        "  res = skimage.transform.resize(predict_mask, (155, 192, 192, 4))\n",
        "  print('Shape after rescale : {}'.format(res.shape))\n",
        "  res = res > 0.5\n",
        "  res = np.argmax(res, axis=-1)\n",
        "  mask[:, 24:-24, 24:-24] = res\n",
        "  mask[mask == 3] = 4\n",
        "  return mask.astype('int')\n",
        "\n",
        "X = load_image(patient)\n",
        "print(X.shape)\n",
        "\n",
        "predict_mask = model.predict(X, batch_size=16)\n",
        "predict_mask = get_mask2original_shape(predict_mask)\n",
        "print(predict_mask.shape)\n",
        "\n",
        "```\n",
        "\n",
        "[Return to code](#scrollTo=cnTIU3BrlhsY&line=8&uniqifier=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JVwUv_NEm8ha"
      },
      "source": [
        "## Exercice 12\n",
        "```python\n",
        "# Compare visual plot of prediction and original mask \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "patient_folder = os.path.join(test_path,patient)\n",
        "orig_image = sitk.ReadImage(os.path.join(patient_folder, \n",
        "                                    patient  + '_seg' + suffix))\n",
        "orig_mask = sitk.GetArrayFromImage(orig_image)\n",
        "\n",
        "z_slice=90\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(orig_mask[z_slice, :,: ], vmin=0, vmax=4)\n",
        "plt.title('Original mask (slice {})'.format(z_slice))\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(predict_mask[z_slice, :,: ], vmin=0, vmax=4)\n",
        "plt.title('Predicted mask (slice {})'.format(z_slice))\n",
        "\n",
        "predict_img = numpy2sitk(predict_mask, orig_image)\n",
        "path = os.path.join(patient_folder, patient + '_predict_seg' + suffix)\n",
        "sitk.WriteImage(predict_img, path)\n",
        "\n",
        "```\n",
        "\n",
        "[Return to code](#scrollTo=hjT3WF0el3yb&line=3&uniqifier=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r_pVQq5zm_3f"
      },
      "source": [
        "## Exercice 13\n",
        "```python\n",
        "wt_dice_list = []\n",
        "et_dice_list = []\n",
        "tc_dice_list = []\n",
        "\n",
        "for patient in patients:\n",
        "\n",
        "  patient_folder = os.path.join(test_path,patient)\n",
        "  orig_image = sitk.ReadImage(os.path.join(patient_folder, \n",
        "                                           patient  + '_seg' + suffix))\n",
        "  orig_mask = sitk.GetArrayFromImage(orig_image)\n",
        "\n",
        "  X = load_image(patient)\n",
        "  predict_mask = model.predict(X, batch_size=16)\n",
        "  predict_mask = get_mask2original_shape(predict_mask)\n",
        "  \n",
        "  print('*********** {} ***********'.format(patient))\n",
        "  scores = evalAllSample(predict_mask, orig_mask)\n",
        "  print(scores)\n",
        "  print()\n",
        "\n",
        "  wt_dice_list.append(scores.loc['Dice', 'wt'])\n",
        "  et_dice_list.append(scores.loc['Dice', 'et'])\n",
        "  tc_dice_list.append(scores.loc['Dice', 'tc'])\n",
        "\n",
        "\n",
        "print('Whole Tumor Dice : {:.2f}'.format(np.mean(wt_dice_list)))\n",
        "print('Tumor Core Dice : {:.2f}'.format(np.mean(et_dice_list)))\n",
        "print('Enhancing Tumor Dice : {:.2f}'.format(np.mean(tc_dice_list)))\n",
        "```\n",
        "\n",
        "[Return to code](#scrollTo=saALPYgDmFzt&line=3&uniqifier=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hk4LQJOXnBaE"
      },
      "source": [
        "## Subsidiary Question\n",
        "```python\n",
        "def unet(input_size = (256,256,1)):\n",
        "  '''\n",
        "    Function taken in : https://github.com/zhixuhao/unet\n",
        "  '''\n",
        "  inputs = Input(input_size)\n",
        "  conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same')(inputs)\n",
        "  conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same')(conv1)\n",
        "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "  conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same')(pool1)\n",
        "  conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same')(conv2)\n",
        "  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "  conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same')(pool2)\n",
        "  conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same')(conv3)\n",
        "  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "  conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same')(pool3)\n",
        "  conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same')(conv4)\n",
        "  drop4 = Dropout(0.5)(conv4)\n",
        "  pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "  conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same')(pool4)\n",
        "  conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same')(conv5)\n",
        "  drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "  up6 = Conv2D(512, 2, activation = 'relu', padding = 'same')(UpSampling2D(size = (2,2))(drop5))\n",
        "  merge6 = concatenate([drop4,up6], axis = 3)\n",
        "  conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same')(merge6)\n",
        "  conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same')(conv6)\n",
        "\n",
        "  up7 = Conv2D(256, 2, activation = 'relu', padding = 'same')(UpSampling2D(size = (2,2))(conv6))\n",
        "  merge7 = concatenate([conv3,up7], axis = 3)\n",
        "  conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same')(merge7)\n",
        "  conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same')(conv7)\n",
        "\n",
        "  up8 = Conv2D(128, 2, activation = 'relu', padding = 'same')(UpSampling2D(size = (2,2))(conv7))\n",
        "  merge8 = concatenate([conv2,up8], axis = 3)\n",
        "  conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same')(merge8)\n",
        "  conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same')(conv8)\n",
        "\n",
        "  up9 = Conv2D(64, 2, activation = 'relu', padding = 'same')(UpSampling2D(size = (2,2))(conv8))\n",
        "  merge9 = concatenate([conv1,up9], axis = 3)\n",
        "  conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same')(merge9)\n",
        "  conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same')(conv9)\n",
        "  conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same')(conv9)\n",
        "  conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
        "\n",
        "  model = Model(input = inputs, output = conv10)\n",
        "\n",
        "  return model \n",
        "```\n",
        "\n",
        "[Return to code](#scrollTo=3YqJqcAxI6Te&line=4&uniqifier=1)"
      ]
    }
  ]
}