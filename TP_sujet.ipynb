{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qABpvWpJ1haY"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/amauryleroy/TP_epu.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmg8tGZM1had"
      },
      "outputs": [],
      "source": [
        "github = False\n",
        "if github:\n",
        "    source = '/content/TP_epu/'\n",
        "else:\n",
        "    source = '.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSyIGHhq1haf"
      },
      "outputs": [],
      "source": [
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install SimpleITK\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install torchsummary\n",
        "!pip install torchviz\n",
        "!pip install albumentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4HNyiEa1hah"
      },
      "source": [
        "  # Part 1 : Study of the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxSql7cl1hal"
      },
      "source": [
        "First, we will study the data.\n",
        "\n",
        "The data is stored in the folder /content/TP_epu/data/\n",
        "\n",
        "For a patient BraTS19_EXAMPLE, you will have a folder /content/TP_epu/data/BraTS19_EXAMPLE. Inside this folder you will have nifti files (.nii.gz) for eacch modalities and each z slice.\n",
        "\n",
        " ## Exercice 1 : Train, Validation and Test Set\n",
        "\n",
        "In this exercise, we will load the train, validation, and test sets and examine their contents. The train, validation and test split are stored in the folder /content/TP_epu/datasets. We store this information under the variable 'path' in the code below. For each split, you will have a text file with a list of patients. For example, the file train.txt contains the list of patients in the train set.\n",
        "\n",
        "1. Load the Data:\n",
        "\n",
        "Complete the following code to load the train, validation, and test sets. Replace 'CompleteHereByAString' with the correct file path for each split. For example, to load the train set, use 'train.txt' as the complete path is '/content/TP_epu/datasets/train.txt' (path variable + 'train.txt').\n",
        "\n",
        "```python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8h99oa31hao"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "path = os.path.join(source, 'datasets/')\n",
        "train_set = np.loadtxt(path + 'CompleteHereByAString', dtype=str)\n",
        "validation_set = np.loadtxt(path + 'CompleteHereByAString', dtype=str)\n",
        "test_set = np.loadtxt(path + 'CompleteHereByAString', dtype=str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6dyPwfM1hap"
      },
      "source": [
        "2. Explore the Train Set:\n",
        "\n",
        "Next, let's print the first 5 patients from the train set. To print in python, you can use the print() function and insert the variable you want to print inside the parenthesis. If it is just text, you need to put it inside quotes. For example, to print the text 'Hello World', you can use the following code: print('Hello World'). You can also print the value of a variable by inserting the variable name inside the parenthesis.\n",
        "You need to replace 'CompleteHereByAList' with the relevant code to print what we want. To retrieve the first five elements of a list, you can use the following syntax: list[:5]. Remember that the train set is a list of patient names and is stored in the variable train_set.\n",
        "Use the code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lB0PzYkR1has"
      },
      "outputs": [],
      "source": [
        "print('Train Set - First 5 Patients:')\n",
        "print('CompleteHereByAList')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogsM3jY91hat"
      },
      "source": [
        "3. Check Set Sizes:\n",
        "\n",
        "Finally, let's calculate and print the lengths of the train, validation, and test sets. Replace 'CompleteHereByCode' with the code to calculate the lengths of the train, validation, and test sets using the appropriate function. To calculate the length of a list, you can use the following syntax: len(list).\n",
        "Complete the code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gd6xiDG1hav"
      },
      "outputs": [],
      "source": [
        "train_size = 'CompleteHereByCode'\n",
        "validation_size = 'CompleteHereByCode'\n",
        "test_size = 'CompleteHereByCode'\n",
        "\n",
        "print('Train Set Size:', train_size)\n",
        "print('Validation Set Size:', validation_size)\n",
        "print('Test Set Size:', test_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "detbGLQK1haw"
      },
      "source": [
        "[Solution](#exercice-1)\n",
        "\n",
        "## Exercice 2 : Content of the data folder\n",
        "\n",
        "In this exercise, we will explore the content of the data folder.\n",
        "\n",
        "Complete the following steps to analyze the data:\n",
        "\n",
        "1. Print the First 5 Patients in the Data Folder:\n",
        "\n",
        "You need to complete the code to print the first 5 patients in the data folder. Use the provided code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpkne3rg1hay"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "data_folder = os.path.join(source, 'data/') # The data is stored in this folder\n",
        "patients = os.listdir(data_folder) # List of all the patients, thanks to the os library and the listdir function.\n",
        "print('First 5 Patients in the Data Folder:')\n",
        "print('CompleteHereByAList')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUuYiLIQ1haz"
      },
      "source": [
        "2. Print the Length of the Data Folder:\n",
        "\n",
        "Next, complete the code to calculate and print the length of the data folder. Replace 'CompleteHereByCode' with the relevant code to calculate the length of the data folder using the appropriate function or method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZujKead1ha1"
      },
      "outputs": [],
      "source": [
        "data_folder_length = 'CompleteHereByCode'\n",
        "print('Data Folder Length:', data_folder_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVEBcL9S1ha2"
      },
      "source": [
        "3. Select a Patient and Print the Number of Images Inside the Patient Folder:\n",
        "\n",
        "\n",
        "Now, we choose a patient (BraTS19_2013_0_1) from the data folder. Complete the code to print the number of images inside the patient folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndmczaFU1ha3"
      },
      "outputs": [],
      "source": [
        "selected_patient = 'BraTS19_2013_0_1/'\n",
        "patient_folder = os.path.join(data_folder, selected_patient) # The os.path.join function allows to concatenate two strings, here the path to the data folder and the name of the patient folder\n",
        "images = os.listdir(patient_folder) # List of all the images of the selected patient\n",
        "num_images = 'CompleteHereByCode'\n",
        "print('Number of Images in Patient Folder:', num_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkaB6Z9y1ha5"
      },
      "source": [
        "4. Print the Number of Z Slices for One Patient:\n",
        "\n",
        "Complete the code to calculate and print the number of z slices for the selected patient. Remember that for one patient, there are 4 modalities (T1, T1ce, T2, FLAIR), each modality has z slices, and there is also a ground truth mask which counts as one supplementary modality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0TI1kM51ha6"
      },
      "outputs": [],
      "source": [
        "num_slices = 'CompleteHereByCode'\n",
        "print('Number of Z Slices for', selected_patient, ':', num_slices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oo7_3q_Y1ha7"
      },
      "source": [
        "5. Print the First 5 Images of a Patient:\n",
        "\n",
        "Lastly, complete the code to print the names of the first 5 images for the selected patient. The 'for' loop will iterate through the first 5 images and print the name of each image as follows: The iterable you need to fill is the list of the first 5 images for the selected patient. The variable 'image' will take the value of each element in the list of the first 5 images for the selected patient. The print() function will print the value of the variable 'image'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERGA3_aT1ha8"
      },
      "outputs": [],
      "source": [
        "print('First 5 Images of', selected_patient, ':')\n",
        "for image in 'CompleteHereByIterable':\n",
        "    print(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPeo2HrA1ha9"
      },
      "source": [
        "[Solution](#exercice-2)\n",
        "## Exercice 3 : Study of medical images\n",
        "\n",
        "In this exercise, we will use the SimpleITK library to study medical images. Medical images are stored in specific data types such as DICOM or NIfTI, which contain not only the images but also medical information. SimpleITK provides convenient functions to work with medical data.\n",
        "\n",
        "In order to accelerate the calculation time and have good results quickly, we work on small images of shape (96, 96). The original images of the dataset have a shape (155, 240, 240) where the 155 correspond to the number of slice on the z axis.\n",
        "\n",
        "\n",
        "The step to pass from the original images to the images we will use are :\n",
        "- Crop the images to a shape of (155, 192, 192)\n",
        "- Downsample the images by interpolation of scale 0.5 (https://scikit-image.org/docs/dev/auto_examples/transform/plot_rescale.html) to a shape of (77, 96, 96)\n",
        "- Save all the z slice independantly in a new array of shape (96, 96).\n",
        "\n",
        "\n",
        "These steps have already been performed for all patients but we kept a small sample of 5 patients stored in the folder /content/TP_epu/original_data which contains the original images. For each patient and each modality, there is a file which corresponds to a single volume of shape (155, 240, 240).\n",
        "\n",
        "\n",
        "The following code aims to perform the following tasks:\n",
        "\n",
        "1. Select one patient from a set of five patients and print the number of images inside the patient folder.\n",
        "2. Print some information about the image, such as geometrical information and pixel value.\n",
        "3. Print the metadata associated with the image.\n",
        "4. Convert the SimpleITK image to a NumPy array.\n",
        "\n",
        "Here is the code. There is nothing to fill in as the students are not required to know the details of SimpleITK library. The code is provided to demonstrate the steps, so just run it and try to understand the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzhGaiRJ1ha-"
      },
      "outputs": [],
      "source": [
        "import SimpleITK as sitk\n",
        "import os\n",
        "\n",
        "orig_data_path = os.path.join(source,'origin_data/')\n",
        "\n",
        "patients = ['BraTS19_CBICA_ANP_1', 'BraTS19_CBICA_AWV_1', 'BraTS19_TCIA01_131_1', 'BraTS19_TCIA10_442_1']\n",
        "modalities = ['_t1', '_t2', '_flair', 't1ce', 'seg']\n",
        "suffix = '.nii.gz'\n",
        "\n",
        "patient = patients[0]\n",
        "modality = modalities[0]\n",
        "\n",
        "patient_folder = os.path.join(orig_data_path, patient)\n",
        "\n",
        "# Use SimpleITK to open the NIfTI image\n",
        "image_path = os.path.join(patient_folder, patient + modality + suffix)\n",
        "image = sitk.ReadImage(image_path)\n",
        "\n",
        "# Print the image type\n",
        "print('Image Type:', type(image))\n",
        "\n",
        "# Print geometrical information\n",
        "print('Image Direction:', image.GetDirection())\n",
        "print('Image Spacing:', image.GetSpacing())\n",
        "print('Image Origin:', image.GetOrigin())\n",
        "\n",
        "# Get the pixel value at coordinate (0, 0, 0)\n",
        "print('Pixel Value at (0, 0, 0):', image.GetPixel(0, 0, 0))\n",
        "\n",
        "# Get all the metadata information\n",
        "metadata = image.GetMetaDataKeys()\n",
        "print('Metadata:')\n",
        "for key in metadata:\n",
        "    value = image.GetMetaData(key)\n",
        "    print('{}: {}'.format(key, value))\n",
        "\n",
        "# Convert the SimpleITK image to a NumPy array\n",
        "array = sitk.GetArrayFromImage(image)\n",
        "print('Array Type:', type(array))\n",
        "print('Array Shape:', array.shape)\n",
        "print('Value at (0, 0, 0) in the Array:', array[0, 0, 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbYyk1UV1ha_"
      },
      "source": [
        "[Solution](#exercice-3)\n",
        "\n",
        "## Exercice 4 : Comparaison between original data and processed data\n",
        "\n",
        "Once we have understood the structure of the data, we will compare the original images and the preprocessed images. As a reminder, the original images are stored in the folder /content/TP_epu/original_data and the preprocessed images are stored in the folder /content/TP_epu/data.\n",
        "\n",
        "Complete the following code to plot side by side one slice of the original images and the preprocessed images. Print also the shape of the original images and the preprocessed images. You should use the functions : sitk.ReadImage, sitk.GetArrayFromImage, shape, plt.imshow, plt.title, plt.subplot.\n",
        "\n",
        "The matplotlib library is used for visualization of images. The function plt.imshow() is used to plot the images. The function plt.title() is used to add a title to the plot. The function plt.subplot() is used to plot multiple images in the same figure. The function plt.show() is used to display the figure.\n",
        "\n",
        "\n",
        "Change the z parameter to plot different slice of the images and observe the differences in the anatomy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkI2-VA61ha_"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "orig_data_path = os.path.join(source, 'origin_data/')\n",
        "patient = patients[0]\n",
        "modality = modalities[0]\n",
        "patient_folder = os.path.join('''CompleteHere''')\n",
        "# We use the librairy sitk to open the nifti images\n",
        "image = sitk.ReadImage(os.path.join('''CompleteHere''', patient + modality + suffix))\n",
        "\n",
        "orig_array = sitk.GetArrayFromImage(image)\n",
        "print('Orig array shape : {}'.format('''CompleteHere'''.shape))\n",
        "\n",
        "###\n",
        "data_path = os.path.join(source, 'data/')\n",
        "patient_folder = os.path.join('''CompleteHere''',patient)\n",
        "z_slice = 35\n",
        "path = os.path.join('''CompleteHere''', patient + modality + '_z_' + str(z_slice) + suffix)\n",
        "image = sitk.ReadImage(path)\n",
        "processed_array = sitk.GetArrayFromImage(image)\n",
        "print('Processed array shape : {}'.format('''CompleteHere'''.shape))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow('''CompleteHere'''[z_slice*2, :, :], cmap='gray')\n",
        "plt.title('''CompleteHere''')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow('''CompleteHere''', cmap='gray')\n",
        "plt.title('''CompleteHere''')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn4i5-iG1hbA"
      },
      "source": [
        "[Solution](#exercice-4)\n",
        "\n",
        "# Part 2: Implementation of the neural network UNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WP7zutL1hbB"
      },
      "source": [
        "## Exercise 5 : Create the UNet Model using PyTorch and a class structure\n",
        "\n",
        "In this exercise, we will construct a U-Net model using the PyTorch library. Unlike other models, U-Net has a unique architecture which looks like a \"U\" as shown in the original U-Net paper. It consists of two paths. First, the contracting path (also known as the encoder) which is used to capture the context in the image. The encoder is just a traditional stack of convolutional and max pooling layers. The second path is the symmetric expanding path (also known as the decoder) which is used to enable precise localization using transposed convolutions.\n",
        "\n",
        "In the following code, we use classes, which is a higher-level structure than definitions. We define a UNet class that builds the architecture of the U-Net model. The constructor (__init__) sets up the layers, and the forward method defines the forward pass, \"what we are really doing with the things we have defined in the __init__\".\n",
        "\n",
        "Here is how we will proceed:\n",
        "\n",
        "- First, we will define a function for a double convolution operation, a common operation in the U-Net architecture. You will need the function nn.Conv2D() from the PyTorch library, which applies a convolution.\n",
        "- Then, we will define a function to create the encoder (down) of the U-Net. The encoder is a stack of convolutional preceded by max pooling layers. You will need the function nn.MaxPool2D() from the PyTorch library, which applies a max pooling operation. The decoder (up) is made of a stack of convolutional layers preceded by a \"up-conv\" layer (upsampling followed by convolution). You will need the function nn.UpSample() from the PyTorch library, which applies an upsampling.\n",
        "- Finally, we will define a function (forward) to build the full U-Net architecture. You will need to use the functions defined in the previous steps and choose the right variable to fill them depending on where you are in the architecture.\n",
        "\n",
        "The forward pass includes the skip connections where the output of a layer is concatenated with the input of a later layer. Finally, we define the model by calling the class and move it to the GPU if one is available.\n",
        "\n",
        "Complete the code at relevant lines by filling in the blanks. For the torch.cat(), the task is to understand which tensors should be concatenated to preserve the local features while upscaling in the decoder part of the U-Net.\n",
        "\n",
        "We define a variable called \"start _channel\" which is the number of channels in the first layer of the U-Net. We set it to 16 as it is sufficient for our task but we may want to increase it for harder tasks as it will make the model more complex and able to learn complex correlations (more parameters because the number of channels is doubled at each layer). We also define a variable called \"num_classes\" which is the number of classes in the output. We set it to 5 because there are 4 possible labels + the background. So the output of the network is a tensor of shape (batch_size, 5, 96, 96), the first dimension is the batch size or number of samples processed by the model at each iteration, the second dimension being the number of classes (the higher value from the five channels is the label the model thinks is the most appropriate for the given pixel), and the last two dimensions being the size of the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sa9zXqbj1hbC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "def double_conv(in_channels, out_channels):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(0.5)\n",
        "            )\n",
        "\n",
        "def down(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.MaxPool2d(2),\n",
        "        double_conv(in_channels, out_channels)\n",
        "    )\n",
        "\n",
        "class up_block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(up_block, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.upsample = nn.Sequential(nn.___(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "                                       nn.___(in_channels,in_channels//2, 2, padding=\"same\"))\n",
        "        self.up_conv = double_conv(self.in_channels, self.out_channels)\n",
        "\n",
        "    def forward(self, x, x_skip):\n",
        "        x = self.upsample(__)\n",
        "        x = torch.cat([__, __], dim=1)\n",
        "        x = self.up_conv(__)\n",
        "        return x\n",
        "\n",
        "start_channel = 16\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        # Define blocks of convolutions\n",
        "        self.inc = double_conv(n_channels, start_channel)\n",
        "        self.down1 = down(start_channel, __)\n",
        "        self.down2 = down(__, __)\n",
        "        self.down3 = down(__, __)\n",
        "        self.up1 = up_block(__, __)\n",
        "        self.up2 = up_block(__, __)\n",
        "        self.up3 = up_block(__, start_channel)\n",
        "        self.outc = nn.Conv2d(start_channel, n_classes, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.__(x1)\n",
        "        x3 = self.__(x2)\n",
        "        x4 = self.__(x3)\n",
        "        x = self.__(x4, x3)\n",
        "        x = self.__(x, x2)\n",
        "        x = self.__(x, x1)\n",
        "        logits = self.__(x)\n",
        "        return logits\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = UNet(n_channels=4, n_classes=5).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7INkX4r1hbD"
      },
      "source": [
        "[Solution](#exercice-5)\n",
        "\n",
        "## Exercice 6 : Study the model\n",
        "\n",
        "The torchsummary library provides a function called summary which gives a nice display of the model architecture, including the output shape of each layer and the number of parameters. Run the following code to display the model summary.\n",
        "\n",
        "Now that we have a nice summary of our model, let's try to answer the following questions:\n",
        "\n",
        "- How many parameters does the model have in total?\n",
        "- What is the shape of the output (also called the embedding) of each layer?\n",
        "- Which layers have the most parameters? Why do you think this is the case?\n",
        "- How does this architecture compare to the one presented in the original U-Net paper? Are there any notable differences?\n",
        "\n",
        "You can find these details in the summary above. It is important to understand how the model's parameters and architecture relate to its performance and computational requirements. Models with more parameters are often more flexible (can fit a wider variety of functions), but they are also more prone to overfitting and require more computational resources.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnB0SkPL1hbE"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(model, input_size=(4, 96, 96))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxA5McPo1hbE"
      },
      "source": [
        "[Solution](#exercice-6)\n",
        "\n",
        "## Exercice 7 : Define the loss function and the optimizer\n",
        "\n",
        "In this exercise, we will define the loss function and the optimizer.\n",
        "\n",
        "Loss Function: This is a measure of how well the neural network is performing. The network will try to minimize this value during training. For our segmentation task, a common loss is the Cross-Entropy Loss. The Cross-Entropy Loss measures the similarity between the predicted class probabilities and the ground truth, pixel per pixel.\n",
        "\n",
        "The Dice coefficient is a common metric for segmentation tasks, that will be useful for us in the validation step. It measures the overlap between the predicted segmentation and the ground truth.  We don't ask you to understand the algorithmic details of the Dice coefficient, but you can read more about it here: https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient\n",
        "\n",
        "Optimizer: This determines how the network will be updated based on the loss function. It implements a specific variant of stochastic gradient descent (SGD). We will use the Adam optimizer.\n",
        "\n",
        "Let's implement these components by filling the blanks. Replace \"CrossEntropyLoss\" with the name of the loss function we want to use. Replace \"Adam\" with the name of the optimizer we want to use, and set learning rate to 0.0005.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItaNQbzN1hbF"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def dice_coefficient(pred, target, smooth=1.):\n",
        "    # One-hot encode the target labels\n",
        "    target_one_hot = torch.zeros_like(pred, dtype=torch.float)\n",
        "    target_one_hot.scatter_(1, target.unsqueeze(1), 1)\n",
        "\n",
        "    # Calculate the Dice loss\n",
        "    intersection = (pred * target_one_hot).sum(dim=(2, 3))\n",
        "    cardinality = pred.sum(dim=(2, 3)) + target_one_hot.sum(dim=(2, 3))\n",
        "\n",
        "    dice = (2. * intersection + smooth) / (cardinality + smooth)\n",
        "    return dice.mean()\n",
        "\n",
        "# Define the loss function\n",
        "loss_function = nn.___(reduction='mean')\n",
        "\n",
        "# Define the optimizer, learning rate and link it to the model\n",
        "\n",
        "optimizer = optim.___(model.parameters(), lr=___)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMzGrPX71hbG"
      },
      "source": [
        "[Solution](#exercice-7)\n",
        "\n",
        "## Exercise 8 : Setting up Dataloaders with Custom Datasets\n",
        "\n",
        "Let's create custom datasets for loading the brain MRI data. It is mandatory to build such functions so that the data that will feed the model is normalzed. We'll write a custom PyTorch Dataset class that reads the image paths from the text files, loads the images and applies the necessary transformations. After that, we will create DataLoaders for training and validation datasets. Dataloaders are used to feed data to the neural network in batches, which is more efficient than feeding the entire dataset at once.\n",
        "\n",
        "We are using Data Augmentation when loading the data. It is the process of modifying the training data, typically in random ways, to produce new training examples. This can include rotation, scaling, and flipping. Data augmentation helps the model generalize better to unseen data.\n",
        "\n",
        "Try to understand how the dataset class is built but we don't ask you to modify it. We first ask you to call the dataset class with the relevant paths. The required parameters are the file lists (text files), the path to the real data and the data augmentation transforms to apply. We also ask you to complete the code to create the train and validation dataloaders. You need to replace \"___\" with the relevant code to create the train and validation dataloaders. You can use the following syntax to create a dataloader: DataLoader(dataset, batch_size=1, shuffle=True). The dataset is the dataset you want to use, the batch_size is the number of samples processed by the model at each iteration (we want a batch size of 128), and shuffle=True means that the data will be shuffled at each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmO79xAz1hbH"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import albumentations as A\n",
        "\n",
        "class BrainMRIDataset(Dataset):\n",
        "    def __init__(self, file_list, data_path, transform=None):\n",
        "        self.data_path = data_path\n",
        "        self.transform = transform\n",
        "\n",
        "        # Read the file_list and store the patient ids\n",
        "        with open(file_list, 'r') as file:\n",
        "            self.patient_ids = file.readlines()\n",
        "\n",
        "        # Define the modalities\n",
        "        self.modalities = ['_t1', '_t2', '_flair', '_t1ce', '_seg']\n",
        "\n",
        "        # List all slices across patients and modalities\n",
        "        self.slice_files = []\n",
        "        for patient_id in self.patient_ids:\n",
        "            patient_id = patient_id.strip()\n",
        "            patient_folder = os.path.join(self.data_path, patient_id)\n",
        "            slice_idx = 0\n",
        "            while True:\n",
        "                slice_files = [os.path.join(patient_folder, f\"{patient_id}{modality}_z_{slice_idx}.nii.gz\")\n",
        "                               for modality in self.modalities]\n",
        "                # Check if the slice files exist\n",
        "                if not all(os.path.exists(slice_file) for slice_file in slice_files):\n",
        "                    break\n",
        "                self.slice_files.append(slice_files)\n",
        "                slice_idx += 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.slice_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the slice files for the given index\n",
        "        slice_files = self.slice_files[idx]\n",
        "\n",
        "        # Read the slices for each modality\n",
        "        slices = []\n",
        "        for slice_file in slice_files:\n",
        "            image = sitk.ReadImage(slice_file)\n",
        "            array = sitk.GetArrayFromImage(image)\n",
        "            slices.append(array)\n",
        "\n",
        "        # Stack the slices for all modalities\n",
        "        data = np.stack(slices)\n",
        "\n",
        "        # The last modality is the segmentation (label)\n",
        "        labels = data[-1]\n",
        "\n",
        "        # Select the other modalities as input\n",
        "        data = data[:-1]\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=data, mask=labels)\n",
        "            data = augmented['image']\n",
        "            labels = augmented['mask']\n",
        "        return data, labels\n",
        "\n",
        "dataset_path = os.path.join(source, 'datasets/')\n",
        "data_path = os.path.join(source, 'data/')\n",
        "\n",
        "def normalize(array):\n",
        "\n",
        "    mean = np.mean(array[array > 0])\n",
        "    std = np.std(array[array > 0])\n",
        "    array = (array - mean) / std\n",
        "    array = np.clip(array, -5, 5)\n",
        "\n",
        "    mini = np.min(array)\n",
        "    maxi = np.max(array)\n",
        "\n",
        "    array = (array - mini) / (maxi - mini)\n",
        "\n",
        "    return array\n",
        "\n",
        "transform = A.Compose([\n",
        "    A.HorizontalFlip(),\n",
        "    A.Rotate(limit = 10),\n",
        "    A.ElasticTransform(),\n",
        "])\n",
        "# , is_check_shapes=False)\n",
        "\n",
        "\n",
        "# Create the dataset\n",
        "train_dataset = BrainMRIDataset(___, ___, transform=transform)\n",
        "val_dataset = BrainMRIDataset(___, ___, transform=transform)\n",
        "test_dataset = BrainMRIDataset(___, ___, transform=None)\n",
        "\n",
        "# Setup the DataLoaders\n",
        "train_dataloader = DataLoader(___, batch_size=___, shuffle=True, num_workers=0)\n",
        "val_dataloader = DataLoader(___, batch_size=___, shuffle=False, num_workers=0)\n",
        "test_dataloader = DataLoader(___, batch_size=___, shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oZ_-P-71hbI"
      },
      "source": [
        "[Solution](#exercice-8)\n",
        "\n",
        "## Exercise 9: Training the model\n",
        "\n",
        "Now that we have defined the model, loss function, optimizer, and data loaders, we are ready to train the model. In this exercise, we will implement the training loop, where the model will learn by iterating over the training data in epochs. After each epoch, we will evaluate the model on the validation dataset. We will also keep track of metrics such as the loss and accuracy during training (with the print statements) and visualize the loss and accuracy curves at the end. Because the training is quite long, we only perform one epoch in this exercise. The process is to first load the data from the train dataloader, then feed the data to the model, then calculate the loss (fill the blank), then backpropagate the loss, and finally update the model parameters. At the end of one training epoch, we evaluate the model on the validation dataset. The mode is then \"eval\" and no more \"train\", so that we don't update parameters anymore on the validation set. It is just for evaluation. We ask you to plot the loss and accuracy curves at the end of the training. You need to replace \"___\" with the relevant code to plot the loss and accuracy curves. You can use the following syntax to plot the loss and accuracy curves: plt.plot(losses, label='Training Loss') and plt.plot(accuracies, label='Training Accuracy'). The losses and accuracies are lists that contain the loss and accuracy values at each iteration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jua3YW5_1hbJ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "\n",
        "# Number of epochs\n",
        "num_epochs = 1\n",
        "\n",
        "# Lists to keep track of metrics\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "val_dice_coefficients = []\n",
        "epoch = 0\n",
        "\n",
        "# Training phase\n",
        "model.train()\n",
        "\n",
        "with tqdm.tqdm(total=len(train_dataloader), desc=f\"Epoch {epoch + 1}/{num_epochs}\", unit=\"batch\") as pbar:\n",
        "    for inputs, labels in train_dataloader:\n",
        "        inputs, labels = inputs.float().to(device), labels.long().to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_function(___, ___)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "        pbar.update(1)\n",
        "        pbar.set_postfix({\"training_loss\": loss.item()})\n",
        "\n",
        "# Validation phase\n",
        "print(\"Validation in progress...\")\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_dataloader:\n",
        "        inputs, labels = inputs.float().to(device), labels.long().to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_function(outputs, labels)\n",
        "        val_losses.append(loss.item())\n",
        "\n",
        "        # Compute accuracy\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct = (preds == labels).sum().item()\n",
        "        total = labels.numel()\n",
        "        accuracy = correct / total\n",
        "        val_accuracies.append(accuracy)\n",
        "\n",
        "        # Compute Dice Coefficient\n",
        "        dice_coeff = dice_coefficient(outputs, labels)\n",
        "        val_dice_coefficients.append(dice_coeff.item())\n",
        "\n",
        "# Calculate average validation loss, accuracy and Dice coefficient\n",
        "train_loss = np.mean(train_losses)\n",
        "val_loss = np.mean(val_losses)\n",
        "val_accuracy = np.mean(val_accuracies)\n",
        "val_dice_coefficient = np.mean(val_dice_coefficients)\n",
        "\n",
        "print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}, Validation Dice Coefficient: {val_dice_coefficient}\")\n",
        "\n",
        "# Plotting the training and validation loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(___, label='Training Loss')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Metric Value')\n",
        "plt.title('Training Loss vs Iteration')\n",
        "plt.show()\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(___, label='Validation Loss')\n",
        "plt.plot(___, label='Validation accuracy')\n",
        "plt.plot(___, label='Validation Dice')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Metric Value')\n",
        "plt.title('Validation Metrics vs Iteration')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULSuOzEh1hbK"
      },
      "source": [
        "[Solution](#exercice-9)\n",
        "\n",
        "## Exercise 10: Make Predictions and Visual Comparison\n",
        "\n",
        "In this part of the exercise, we will use a pre-trained U-Net model. This model has already been trained on the same dataset of brain images abut with much more iterations until convergence. We provide it to you since the full training lasts around 12 hours.\n",
        "\n",
        "We have also stored the predictions of this model for the test set in the folder \"/test\". We will perform a visual comparison of the predicted tumor masks against the ground truth by plotting them side by side.\n",
        "\n",
        "Task:\n",
        "Use the model and load predictions on the test.\n",
        "Plot some examples side by side for visual comparison (original images vs. predicted mask vs. ground truth)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gS4qZJ51hbL"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "mods = [\"t1\", \"t2\", \"flair\", \"t1ce\"]\n",
        "\n",
        "num_predictions = 10\n",
        "n = 0\n",
        "# Make predictions and plot them against the ground truth\n",
        "while n < num_predictions:\n",
        "    num_slice = random.randint(0, 870)\n",
        "    inputs = [np.load(os.path.join(source, 'test/input_{}_{}.npy'.format(num_slice,mods[j]))) for j in range(4)]\n",
        "    labels = np.load(os.path.join(source, 'test/label_{}.npy'.format(num_slice)))\n",
        "    predictions = np.load(os.path.join(source, 'test/prediction_{}.npy'.format(num_slice)))\n",
        "    if labels.sum() > 0:\n",
        "\n",
        "        # Plot the input modalities\n",
        "        plt.figure(figsize=(20, 10))\n",
        "        for i in range(4):\n",
        "            plt.subplot(1, 6, i+1)\n",
        "            plt.imshow(___, cmap='gray')\n",
        "            plt.title(mods[i])\n",
        "            plt.axis('off')\n",
        "        # Plot the predicted mask and the ground truth\n",
        "        plt.subplot(1, 6, 5)\n",
        "        plt.imshow(___)\n",
        "        plt.title('Predicted Mask')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 6, 6)\n",
        "        plt.imshow(___)\n",
        "        plt.title('Ground Truth')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()\n",
        "        n+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWt5vz6_1hbM"
      },
      "source": [
        "[Solution](#exercice-10)\n",
        "\n",
        "## Exercise 11: Compute and Understand Metrics\n",
        "In this part, we will compute the evaluation metrics for our predictions. We will compute True Positive (TP), False Positive (FP), False Negative (FN), and True Negative (TN) rates. Based on these, we will calculate the Sensitivity, Specificity, and Dice Coefficient. Here's how these metrics are calculated:\n",
        "\n",
        "Sensitivity (Recall) = TP / (TP + FN)\n",
        "Specificity = TN / (TN + FP)\n",
        "Dice Coefficient = 2 * TP / (2 * TP + FP + FN)\n",
        "We will compute these metrics for three categories:\n",
        "\n",
        "Whole tumor (labels 1,2,4)\n",
        "Tumor core (labels 1 and 4)\n",
        "Enhancing tumor (label 4)\n",
        "Task:\n",
        "Compute the TP, FP, FN, TN rates.\n",
        "Calculate the Sensitivity, Specificity, and Dice Coefficient using the above formulas.\n",
        "Display the results in a table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x17kTcBO1hbM"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=int(len(test_dataset)/10), shuffle=False, num_workers=0)\n",
        "# print the size of the test dataset\n",
        "# Create arrays to store the metrics for each category\n",
        "sensitivities = []\n",
        "specificities = []\n",
        "dices = []\n",
        "\n",
        "# Define the label categories\n",
        "categories = [(1, 2, 4), (1, 4), (4,)]\n",
        "mods = [\"t1\", \"t2\", \"flair\", \"t1ce\"]\n",
        "# Calculate metrics for each category\n",
        "for category in categories:\n",
        "    # Initialize counters\n",
        "    TP = FP = FN = TN = 0\n",
        "\n",
        "    # Iterate through the test set\n",
        "    for i in range(int(len(os.listdir(os.path.join(source, 'test/')))/6)):\n",
        "\n",
        "        labels = np.load(os.path.join(source, 'test/label_{}.npy'.format(i)))\n",
        "        predictions = np.load(os.path.join(source, 'test/prediction_{}.npy'.format(i)))\n",
        "\n",
        "\n",
        "        # Update counters\n",
        "        c_matrix = confusion_matrix((labels[..., np.newaxis] == category).ravel(), (predictions[..., np.newaxis] == category).ravel())\n",
        "        # handle the case if there is only one label so the confusion matrix is 1x1\n",
        "        if c_matrix.shape == (1, 1):\n",
        "            c_matrix = np.array([[c_matrix[0, 0], 0], [0, 0]])\n",
        "\n",
        "        TP += c_matrix[1, 1]\n",
        "        FP += c_matrix[0, 1]\n",
        "        FN += c_matrix[1, 0]\n",
        "        TN += c_matrix[0, 0]\n",
        "\n",
        "    # Calculate metrics\n",
        "    sensitivity = ___\n",
        "    specificity = ___\n",
        "    dice = ___\n",
        "\n",
        "    # Append to results\n",
        "    sensitivities.append(sensitivity)\n",
        "    specificities.append(specificity)\n",
        "    dices.append(dice)\n",
        "\n",
        "# Display results in a table\n",
        "import pandas as pd\n",
        "\n",
        "data = {'Category': ['Whole Tumor', 'Tumor Core', 'Enhancing Tumor'],\n",
        "        'Sensitivity': ___,\n",
        "        'Specificity': ___,\n",
        "        'Dice Coefficient': ___}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPOVfxYj1hbf"
      },
      "source": [
        "# Part 6 : Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQLackNe1hbg"
      },
      "source": [
        " ## Exercice 1\n",
        "\n",
        "[Return to code](#exercice-1-:-train,-validation-and-test-set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4o_8upEk1hbh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "path = os.path.join(source, 'datasets/')\n",
        "\n",
        "train_set = np.loadtxt(path + 'train.txt', dtype=str)\n",
        "validation_set = np.loadtxt(path + 'val.txt', dtype=str)\n",
        "test_set = np.loadtxt(path + 'test.txt', dtype=str)\n",
        "\n",
        "# Train_set, validation_set, and test_set are lists of patients\n",
        "print('Train Set - First 5 Patients:')\n",
        "print(train_set[:5])\n",
        "\n",
        "train_size = len(train_set)\n",
        "validation_size = len(validation_set)\n",
        "test_size = len(test_set)\n",
        "\n",
        "print('Train Set Size:', train_size)\n",
        "print('Validation Set Size:', validation_size)\n",
        "print('Test Set Size:', test_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LO7oqrwE1hbi"
      },
      "source": [
        " ## Exercice 2\n",
        "\n",
        "[Return to code](#exercice-2-:-content-of-the-data-folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cur7jOL71hbj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "data_folder = os.path.join(source, 'data/')\n",
        "\n",
        "patients = os.listdir(data_folder)\n",
        "print('First 5 Patients in the Data Folder:')\n",
        "print(patients[:5])\n",
        "\n",
        "data_folder_length = len(patients)\n",
        "print('Data Folder Length:', data_folder_length)\n",
        "\n",
        "selected_patient = 'BraTS19_2013_0_1/'\n",
        "patient_folder = os.path.join(data_folder, selected_patient)\n",
        "images = os.listdir(patient_folder)\n",
        "num_images = len(images)\n",
        "print('Number of Images in Patient Folder:', num_images)\n",
        "\n",
        "num_slices = len(images) /5\n",
        "print('Number of Z Slices for', selected_patient, ':', num_slices)\n",
        "\n",
        "print('First 5 Images of', selected_patient, ':')\n",
        "for image in images[:5]:\n",
        "    print(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j7HanyZ1hbk"
      },
      "source": [
        "## Exercice 3\n",
        "\n",
        "[Return to code](#exercice-3-:-study-of-medical-images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hD-XjJ9x1hbk"
      },
      "outputs": [],
      "source": [
        "import SimpleITK as sitk\n",
        "import os\n",
        "\n",
        "orig_data_path = os.path.join(source, 'origin_data/')\n",
        "\n",
        "patients = ['BraTS19_CBICA_ANP_1', 'BraTS19_CBICA_AWV_1', 'BraTS19_TCIA01_131_1', 'BraTS19_TCIA10_442_1']\n",
        "modalities = ['_t1', '_t2', '_flair', 't1ce', 'seg']\n",
        "suffix = '.nii.gz'\n",
        "\n",
        "patient = patients[0]\n",
        "modality = modalities[0]\n",
        "\n",
        "patient_folder = os.path.join(orig_data_path, patient)\n",
        "\n",
        "# Use SimpleITK to open the NIfTI image\n",
        "image_path = os.path.join(patient_folder, patient + modality + suffix)\n",
        "image = sitk.ReadImage(image_path)\n",
        "\n",
        "# Print the image type\n",
        "print('Image Type:', type(image))\n",
        "\n",
        "# Print geometrical information\n",
        "print('Image Direction:', image.GetDirection())\n",
        "print('Image Spacing:', image.GetSpacing())\n",
        "print('Image Origin:', image.GetOrigin())\n",
        "\n",
        "# Get the pixel value at coordinate (0, 0, 0)\n",
        "print('Pixel Value at (0, 0, 0):', image.GetPixel(0, 0, 0))\n",
        "\n",
        "# Get all the metadata information\n",
        "metadata = image.GetMetaDataKeys()\n",
        "print('Metadata:')\n",
        "for key in metadata:\n",
        "    value = image.GetMetaData(key)\n",
        "    print('{}: {}'.format(key, value))\n",
        "\n",
        "# Convert the SimpleITK image to a NumPy array\n",
        "array = sitk.GetArrayFromImage(image)\n",
        "print('Array Type:', type(array))\n",
        "print('Array Shape:', array.shape)\n",
        "print('Value at (0, 0, 0) in the Array:', array[0, 0, 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhDflUYv1hbm"
      },
      "source": [
        "## Exercice 4\n",
        "\n",
        "[Return to code](#exercice-4-:-comparaison-between-original-data-and-processed-data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDhEFeOg1hbn"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "orig_data_path = os.path.join(source, 'origin_data/')\n",
        "\n",
        "patient = patients[0]\n",
        "modality = modalities[0]\n",
        "patient_folder = os.path.join(orig_data_path,patient)\n",
        "# We use the librairy sitk to open the nifti images\n",
        "image = sitk.ReadImage(os.path.join(patient_folder, patient + modality + suffix))\n",
        "orig_array = sitk.GetArrayFromImage(image)\n",
        "print('Orig array shape : {}'.format(orig_array.shape))\n",
        "\n",
        "\n",
        "data_path = os.path.join(source, 'data')\n",
        "patient_folder = os.path.join(data_path,patient)\n",
        "z_slice = 35\n",
        "path = os.path.join(patient_folder, patient + modality + '_z_' + str(z_slice) + suffix)\n",
        "image = sitk.ReadImage(path)\n",
        "processed_array = sitk.GetArrayFromImage(image)\n",
        "print('Processed array shape : {}'.format(processed_array.shape))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(orig_array[z_slice*2, :, :], cmap='gray')\n",
        "plt.title('Original array')\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(processed_array, cmap='gray')\n",
        "plt.title('Processed array')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9ADt17X1hbo"
      },
      "source": [
        "## Exercice 5  \n",
        "\n",
        "[Return to code](#exercice-5-:-create-the-unet-model-using-pytorch-and-a-class-structure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "clqZIZYN1hbp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "def double_conv(in_channels, out_channels):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout(0.5)\n",
        "            )\n",
        "\n",
        "def down(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.MaxPool2d(2),\n",
        "        double_conv(in_channels, out_channels)\n",
        "    )\n",
        "\n",
        "class up_block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(up_block, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.upsample = nn.Sequential(nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "                                       nn.Conv2d(in_channels,in_channels//2, 2, padding=\"same\"))\n",
        "        self.up_conv = double_conv(self.in_channels, self.out_channels)\n",
        "\n",
        "    def forward(self, x, x_skip):\n",
        "        x = self.upsample(x)\n",
        "        x = torch.cat([x, x_skip], dim=1)\n",
        "        x = self.up_conv(x)\n",
        "        return x\n",
        "\n",
        "start_channel = 16\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        # Define blocks of convolutions\n",
        "        self.inc = double_conv(n_channels, start_channel)\n",
        "        self.down1 = down(start_channel, start_channel*2)\n",
        "        self.down2 = down(start_channel*2, start_channel*4)\n",
        "        self.down3 = down(start_channel*4, start_channel*8)\n",
        "        self.up1 = up_block(start_channel*8, start_channel*4)\n",
        "        self.up2 = up_block(start_channel*4, start_channel*2)\n",
        "        self.up3 = up_block(start_channel*2, start_channel)\n",
        "        self.outc = nn.Conv2d(start_channel, n_classes, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x = self.up1(x4, x3)\n",
        "        x = self.up2(x, x2)\n",
        "        x = self.up3(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = UNet(n_channels=4, n_classes=5).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGQ6bPuH1hbq"
      },
      "source": [
        "## Exercice 6  \n",
        "\n",
        "[Return to code](#exercice-6-:-study-the-model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxpTmZEi1hbr"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(model, input_size=(4, 96, 96))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKme_Yt_1hbs"
      },
      "source": [
        "## Exercice 7\n",
        "\n",
        "[Return to code](#exercice-7-:-define-the-loss-function-and-the-optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkX-5OAI1hbt"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Define the dice coefficient metric for validation\n",
        "def dice_coefficient(pred, target, smooth=1.):\n",
        "    # One-hot encode the target labels\n",
        "    target_one_hot = torch.zeros_like(pred, dtype=torch.float)\n",
        "    target_one_hot.scatter_(1, target.unsqueeze(1), 1)\n",
        "\n",
        "    # Calculate the Dice loss\n",
        "    intersection = (pred * target_one_hot).sum(dim=(2, 3))\n",
        "    cardinality = pred.sum(dim=(2, 3)) + target_one_hot.sum(dim=(2, 3))\n",
        "\n",
        "    dice = (2. * intersection + smooth) / (cardinality + smooth)\n",
        "    return dice.mean()\n",
        "\n",
        "# Define the loss function\n",
        "loss_function = nn.CrossEntropyLoss(reduction='mean')\n",
        "\n",
        "# Define the optimizer, learning rate and link it to the model\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zvmlWPt1hbu"
      },
      "source": [
        "## Exercise 8\n",
        "\n",
        "[Return to code](#exercice-8-:-setting-up-dataloaders-with-custom-datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFSL5HGm1hbv"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import albumentations as A\n",
        "\n",
        "class BrainMRIDataset(Dataset):\n",
        "    def __init__(self, file_list, data_path, transform=None):\n",
        "        self.data_path = data_path\n",
        "        self.transform = transform\n",
        "\n",
        "        # Read the file_list and store the patient ids\n",
        "        with open(file_list, 'r') as file:\n",
        "            self.patient_ids = file.readlines()\n",
        "\n",
        "        # Define the modalities\n",
        "        self.modalities = ['_t1', '_t2', '_flair', '_t1ce', '_seg']\n",
        "\n",
        "        # List all slices across patients and modalities\n",
        "        self.slice_files = []\n",
        "        for patient_id in self.patient_ids:\n",
        "            patient_id = patient_id.strip()\n",
        "            patient_folder = os.path.join(self.data_path, patient_id)\n",
        "            slice_idx = 0\n",
        "            while True:\n",
        "                slice_files = [os.path.join(patient_folder, f\"{patient_id}{modality}_z_{slice_idx}.nii.gz\")\n",
        "                               for modality in self.modalities]\n",
        "                # Check if the slice files exist\n",
        "                if not all(os.path.exists(slice_file) for slice_file in slice_files):\n",
        "                    break\n",
        "                self.slice_files.append(slice_files)\n",
        "                slice_idx += 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.slice_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the slice files for the given index\n",
        "        slice_files = self.slice_files[idx]\n",
        "\n",
        "        # Read the slices for each modality\n",
        "        slices = []\n",
        "        for slice_file in slice_files:\n",
        "            image = sitk.ReadImage(slice_file)\n",
        "            array = sitk.GetArrayFromImage(image)\n",
        "            slices.append(array)\n",
        "\n",
        "        # Stack the slices for all modalities\n",
        "        data = np.stack(slices)\n",
        "\n",
        "        # The last modality is the segmentation (label)\n",
        "        labels = data[-1]\n",
        "\n",
        "        # Select the other modalities as input\n",
        "        data = data[:-1]\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=data, mask=labels)\n",
        "            data = augmented['image']\n",
        "            labels = augmented['mask']\n",
        "        return data, labels\n",
        "\n",
        "\n",
        "dataset_path = os.path.join(source, 'datasets/')\n",
        "data_path = os.path.join(source, 'data/')\n",
        "\n",
        "def normalize(array):\n",
        "\n",
        "    mean = np.mean(array[array > 0])\n",
        "    std = np.std(array[array > 0])\n",
        "    array = (array - mean) / std\n",
        "    array = np.clip(array, -5, 5)\n",
        "\n",
        "    mini = np.min(array)\n",
        "    maxi = np.max(array)\n",
        "\n",
        "    array = (array - mini) / (maxi - mini)\n",
        "\n",
        "    return array\n",
        "\n",
        "transform = A.Compose([\n",
        "    A.HorizontalFlip(),\n",
        "    A.Rotate(limit = 10),\n",
        "    A.ElasticTransform(),\n",
        "])\n",
        "# , is_check_shapes=False)\n",
        "\n",
        "\n",
        "\n",
        "# Create the dataset\n",
        "train_dataset = BrainMRIDataset(os.path.join(dataset_path, 'train.txt'), data_path, transform=transform)\n",
        "val_dataset = BrainMRIDataset(os.path.join(dataset_path, 'val.txt'), data_path, transform=transform)\n",
        "test_dataset = BrainMRIDataset(os.path.join(dataset_path, 'test.txt'), data_path, transform=None)\n",
        "\n",
        "batch_size = 128\n",
        "# Setup the DataLoaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh2LbBFd1hbw"
      },
      "source": [
        "## Exercise 9\n",
        "\n",
        "[Return to code](#exercice-9-:-training-the-model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4P2fRuvV1hbx"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "\n",
        "# Number of epochs\n",
        "num_epochs = 1\n",
        "\n",
        "# Lists to keep track of metrics\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "val_dice_coefficients = []\n",
        "epoch = 0\n",
        "\n",
        "# Training phase\n",
        "model.train()\n",
        "\n",
        "with tqdm.tqdm(total=len(train_dataloader), desc=f\"Epoch {epoch + 1}/{num_epochs}\", unit=\"batch\") as pbar:\n",
        "    for inputs, labels in train_dataloader:\n",
        "        inputs, labels = inputs.float().to(device), labels.long().to(device)\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_function(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "        pbar.update(1)\n",
        "        pbar.set_postfix({\"training_loss\": loss.item()})\n",
        "\n",
        "# Validation phase\n",
        "print(\"Validation in progress...\")\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_dataloader:\n",
        "        inputs, labels = inputs.float().to(device), labels.long().to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_function(outputs, labels)\n",
        "        val_losses.append(loss.item())\n",
        "\n",
        "        # Compute accuracy\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct = (preds == labels).sum().item()\n",
        "        total = labels.numel()\n",
        "        accuracy = correct / total\n",
        "        val_accuracies.append(accuracy)\n",
        "\n",
        "        # Compute Dice Coefficient\n",
        "        dice_coeff = dice_coefficient(outputs, labels)\n",
        "        val_dice_coefficients.append(dice_coeff.item())\n",
        "\n",
        "# Calculate average validation loss, accuracy and Dice coefficient\n",
        "train_loss = np.mean(train_losses)\n",
        "val_loss = np.mean(val_losses)\n",
        "val_accuracy = np.mean(val_accuracies)\n",
        "val_dice_coefficient = np.mean(val_dice_coefficients)\n",
        "\n",
        "print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss}, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}, Validation Dice Coefficient: {val_dice_coefficient}\")\n",
        "\n",
        "# Plotting the training and validation loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Metric Value')\n",
        "plt.title('Training Loss vs Iteration')\n",
        "plt.show()\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.plot(val_accuracies, label='Validation accuracy')\n",
        "plt.plot(val_dice_coefficients, label='Validation Dice')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Metric Value')\n",
        "plt.title('Validation Metrics vs Iteration')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kctO3wx1hbz"
      },
      "source": [
        "[Return to code](#exercise-10-:make-predictions-and-visual-comparison)\n",
        "# Exercise 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UttT_j9G1hb1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "mods = [\"t1\", \"t2\", \"flair\", \"t1ce\"]\n",
        "\n",
        "num_predictions = 10\n",
        "n = 0\n",
        "# Make predictions and plot them against the ground truth\n",
        "while n < num_predictions:\n",
        "    num_slice = random.randint(0, 870)\n",
        "    inputs = [np.load(os.path.join(source, 'test/input_{}_{}.npy'.format(num_slice,mods[j]))) for j in range(4)]\n",
        "    labels = np.load(os.path.join(source, 'test/label_{}.npy'.format(num_slice)))\n",
        "    predictions = np.load(os.path.join(source, 'test/prediction_{}.npy'.format(num_slice)))\n",
        "    if labels.sum() > 0:\n",
        "\n",
        "        # Plot the input modalities\n",
        "        plt.figure(figsize=(20, 10))\n",
        "        for i in range(4):\n",
        "            plt.subplot(1, 6, i+1)\n",
        "            plt.imshow(inputs[i], cmap='gray')\n",
        "            plt.title(mods[i])\n",
        "            plt.axis('off')\n",
        "        # Plot the predicted mask and the ground truth\n",
        "        plt.subplot(1, 6, 5)\n",
        "        plt.imshow(predictions)\n",
        "        plt.title('Predicted Mask')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 6, 6)\n",
        "        plt.imshow(labels)\n",
        "        plt.title('Ground Truth')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()\n",
        "        n+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMvTAlz-1hb2"
      },
      "source": [
        "# Exercise 11\n",
        "\n",
        "[Return to code](#exercise-11:-compute-and-understand-metrics)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDLAVRIO1hb3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=int(len(test_dataset)/10), shuffle=False, num_workers=0)\n",
        "# Create arrays to store the metrics for each category\n",
        "sensitivities = []\n",
        "specificities = []\n",
        "dices = []\n",
        "\n",
        "# Define the label categories\n",
        "categories = [(1, 2, 4), (1, 4), (4,)]\n",
        "mods = [\"t1\", \"t2\", \"flair\", \"t1ce\"]\n",
        "# Calculate metrics for each category\n",
        "for category in categories:\n",
        "    # Initialize counters\n",
        "    TP = FP = FN = TN = 0\n",
        "\n",
        "    # Iterate through the test set\n",
        "    for i in range(int(len(os.listdir(os.path.join(source, 'test/')))/6)):\n",
        "\n",
        "        labels = np.load(os.path.join(source, 'test/label_{}.npy'.format(i)))\n",
        "        predictions = np.load(os.path.join(source, 'test/prediction_{}.npy'.format(i)))\n",
        "\n",
        "\n",
        "        # Update counters\n",
        "        c_matrix = confusion_matrix((labels[..., np.newaxis] == category).ravel(), (predictions[..., np.newaxis] == category).ravel())\n",
        "        # handle the case if there is only one label so the confusion matrix is 1x1\n",
        "        if c_matrix.shape == (1, 1):\n",
        "            c_matrix = np.array([[c_matrix[0, 0], 0], [0, 0]])\n",
        "        TP += c_matrix[1, 1]\n",
        "        FP += c_matrix[0, 1]\n",
        "        FN += c_matrix[1, 0]\n",
        "        TN += c_matrix[0, 0]\n",
        "\n",
        "    # Calculate metrics\n",
        "    sensitivity = TP / (TP + FN)\n",
        "    specificity = TN / (TN + FP)\n",
        "    dice = 2 * TP / (2 * TP + FP + FN)\n",
        "\n",
        "    # Append to results\n",
        "    sensitivities.append(sensitivity)\n",
        "    specificities.append(specificity)\n",
        "    dices.append(dice)\n",
        "\n",
        "# Display results in a table\n",
        "import pandas as pd\n",
        "\n",
        "data = {'Category': ['Whole Tumor', 'Tumor Core', 'Enhancing Tumor'],\n",
        "        'Sensitivity': sensitivities,\n",
        "        'Specificity': specificities,\n",
        "        'Dice Coefficient': dices}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
